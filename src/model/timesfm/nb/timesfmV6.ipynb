{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af590bef",
   "metadata": {},
   "source": [
    "# TimesFM 2.5 (PyTorch) による Loto データ予測の動作確認\n",
    "\n",
    "**目的**:\n",
    "ローカルの PostgreSQL データベース (`dataset.loto_y_ts`) からデータを取得し、`loto` (ロト種別) および `ts_type` (時系列タイプ) ごとに `y` (値) の将来予測を行います。\n",
    "\n",
    "**環境**:\n",
    "- Model: TimesFM 2.5 (200M parameters, PyTorch version)\n",
    "- Data Source: Local PostgreSQL (`dataset.loto_y_ts`)\n",
    "- Path: `/mnt/e/env/ts/lib_ana/src/model/timesfm/timesfmV2.ipynb`\n",
    "\n",
    "**前提条件**:\n",
    "- 必要なライブラリ (`torch`, `pandas`, `numpy`, `sqlalchemy`, `psycopg2-binary`, `timesfm` 等) がインストールされていること。\n",
    "- Hugging Face のモデル `google/timesfm-2.5-200m-pytorch` へのアクセスが可能であること。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "125f4375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.14 (main, Oct 21 2025, 18:31:21) [GCC 11.2.0]\n",
      "Torch: 2.4.1+cu121\n",
      "CUDA Available: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sqlalchemy import create_engine\n",
    "from textwrap import dedent\n",
    "\n",
    "# timesfm モジュールがパスに通っているか確認してください\n",
    "# 必要であれば sys.path.append() で調整します\n",
    "# sys.path.append(\"../../../\") \n",
    "\n",
    "import timesfm\n",
    "\n",
    "# ログ設定の抑制（任意）\n",
    "import logging\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"Torch: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7f68de",
   "metadata": {},
   "source": [
    "## データベースからのデータ取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6980f4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from database...\n",
      "Data loaded successfully. Shape: (456096, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loto</th>\n",
       "      <th>ts_type</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bingo5</td>\n",
       "      <td>cumsum</td>\n",
       "      <td>2017-04-05</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bingo5</td>\n",
       "      <td>cumsum</td>\n",
       "      <td>2017-04-05</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bingo5</td>\n",
       "      <td>cumsum</td>\n",
       "      <td>2017-04-05</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bingo5</td>\n",
       "      <td>cumsum</td>\n",
       "      <td>2017-04-05</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bingo5</td>\n",
       "      <td>cumsum</td>\n",
       "      <td>2017-04-05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     loto ts_type          ds     y\n",
       "0  bingo5  cumsum  2017-04-05  10.0\n",
       "1  bingo5  cumsum  2017-04-05  19.0\n",
       "2  bingo5  cumsum  2017-04-05  13.0\n",
       "3  bingo5  cumsum  2017-04-05  23.0\n",
       "4  bingo5  cumsum  2017-04-05   1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# データベース接続情報の定義\n",
    "DB_CONFIG = {\n",
    "    \"user\": \"loto\",\n",
    "    \"password\": \"z\",\n",
    "    \"host\": \"127.0.0.1\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"loto\"\n",
    "}\n",
    "\n",
    "# 接続文字列の作成 (PostgreSQL)\n",
    "db_url = f\"postgresql+psycopg2://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "\n",
    "# エンジンの作成\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "# データ取得クエリ\n",
    "# loto, ts_type ごとに時系列順 (ds) にデータを取得します\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    loto,\n",
    "    ts_type,\n",
    "    ds,\n",
    "    y\n",
    "FROM\n",
    "    dataset.loto_y_ts\n",
    "ORDER BY\n",
    "    loto,\n",
    "    ts_type,\n",
    "    ds ASC\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    print(\"Fetching data from database...\")\n",
    "    df = pd.read_sql(query, engine)\n",
    "    print(f\"Data loaded successfully. Shape: {df.shape}\")\n",
    "    display(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f38a08",
   "metadata": {},
   "source": [
    "## データのバッチ化とアテンションマスクの作成\n",
    "\n",
    "ロードしたデータフレーム (`df`) は「ロング形式」であり、系列ごとに長さが異なる可能性があります。\n",
    "TimesFM などの Transformer モデルに入力するため、以下の前処理を行います。\n",
    "\n",
    "1.  **グルーピング**: `loto` と `ts_type` の組み合わせごとに時系列データを抽出します。\n",
    "2.  **左パディング (Left Padding)**: バッチ内の最大系列長に合わせて、各系列の先頭（過去側）を埋めます。これは、因果的マスク(Causal Mask)を適用する時系列モデルで一般的です。\n",
    "3.  **マスク情報の生成**: 各系列で「どれだけパディングしたか」を `num_all_masked_kv` として計算し、`make_attn_mask` に渡します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfcfd4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 36, Max sequence length: 27664\n",
      "------------------------------\n",
      "Mask shape: (36, 1, 27664, 27664)\n",
      "Sample mask (first batch item):\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ...  True False False]\n",
      " [False False False ...  True  True False]\n",
      " [False False False ...  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from timesfm.flax.transformer import make_attn_mask\n",
    "\n",
    "# 1. データを系列ごとに分割・リスト化\n",
    "# (loto, ts_type) をキーとして、yの値を時系列順(ds順)に抽出\n",
    "grouped = df.groupby(['loto', 'ts_type'])\n",
    "sequences = [group['y'].values for _, group in grouped]\n",
    "\n",
    "# 2. バッチ内の最大長(max_len)を計算\n",
    "# これが query_length (入力シーケンス長) になります\n",
    "max_len = max(len(seq) for seq in sequences)\n",
    "batch_size = len(sequences)\n",
    "\n",
    "print(f\"Batch size: {batch_size}, Max sequence length: {max_len}\")\n",
    "\n",
    "# 3. 左パディング処理とパディング数の計算\n",
    "# Transformerへの入力配列 (batch, length) と、パディング数 (batch,) を用意\n",
    "batched_input = np.zeros((batch_size, max_len), dtype=np.float32)\n",
    "num_all_masked_kv_list = []\n",
    "\n",
    "for i, seq in enumerate(sequences):\n",
    "    seq_len = len(seq)\n",
    "    # 左パディング数 = 最大長 - 現在の系列長\n",
    "    pad_len = max_len - seq_len\n",
    "    num_all_masked_kv_list.append(pad_len)\n",
    "    \n",
    "    # 配列の右側（直近）にデータを配置し、左側（過去）は0埋め\n",
    "    if seq_len > 0:\n",
    "        batched_input[i, pad_len:] = seq\n",
    "\n",
    "# JAX配列(DeviceArray)へ変換\n",
    "# num_all_masked_kv は int32 である必要があります\n",
    "num_all_masked_kv = jnp.array(num_all_masked_kv_list, dtype=jnp.int32)\n",
    "batched_input_jax = jnp.array(batched_input) # ※実際のモデル入力用\n",
    "\n",
    "# 4. アテンションマスクの作成\n",
    "# query_length は Pythonの int (static) で渡す必要があります\n",
    "result_mask = make_attn_mask(\n",
    "    query_length=int(max_len),          # バッチ内の最大系列長\n",
    "    num_all_masked_kv=num_all_masked_kv, # 各バッチの左パディング数\n",
    "    query_index_offset=None,            # 通常推論(キャッシュなし)ならNoneでOK\n",
    "    kv_length=0,                        # 0なら自己注意 (kv_length=query_length)\n",
    ")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Mask shape: {result_mask.shape}\") # (Batch, 1, Query, Key)\n",
    "print(f\"Sample mask (first batch item):\\n{result_mask[0, 0, :, :]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f77926",
   "metadata": {},
   "source": [
    "## RevIN (Reverse Instance Normalization) の適用\n",
    "\n",
    "モデルの学習安定性と予測精度を向上させるため、入力データに対して正規化を行います。\n",
    "RevINでは、入力系列ごとの平均($\\mu$)と標準偏差($\\sigma$)を用いて正規化し、推論後の出力に対して逆変換（非正規化）を行うことで元のスケールに戻します。\n",
    "\n",
    "ここでは、入力データ `batched_input_jax` から統計量を算出し、正規化を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58f5cbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original stats - Mean: 618.1191, Std: 2163.3667\n",
      "Normalized input shape: (36, 27664)\n",
      "Normalized sample (first 5): [-0.2857209 -0.2857209 -0.2857209 -0.2857209 -0.2857209]\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "from timesfm.flax.util import revin\n",
    "\n",
    "# 1. 統計量（平均と標準偏差）の計算\n",
    "# 時間軸 (axis=1) に沿って計算し、ブロードキャスト用に次元を保持 (keepdims=True) します。\n",
    "# input shape: [Batch, Time] -> stats shape: [Batch, 1]\n",
    "mu = jnp.mean(batched_input_jax, axis=1, keepdims=True)\n",
    "sigma = jnp.std(batched_input_jax, axis=1, keepdims=True)\n",
    "\n",
    "# ゼロ除算を防ぐための微小値加算（一般的に行われる処理ですが、データにより調整）\n",
    "eps = 1e-5\n",
    "sigma = jnp.maximum(sigma, eps)\n",
    "\n",
    "# 2. 正規化 (Normalization) の実行\n",
    "# TODO の箇所を埋めています\n",
    "normalized_input = revin(\n",
    "    x=batched_input_jax,  # Float[Array, 'batch time']\n",
    "    mu=mu,                # Float[Array, 'batch 1']\n",
    "    sigma=sigma,          # Float[Array, 'batch 1']\n",
    "    reverse=False,        # False = 正規化 (Input -> Normalized)\n",
    ")\n",
    "\n",
    "print(f\"Original stats - Mean: {mu[0,0]:.4f}, Std: {sigma[0,0]:.4f}\")\n",
    "print(f\"Normalized input shape: {normalized_input.shape}\")\n",
    "print(f\"Normalized sample (first 5): {normalized_input[0, :5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54008ac3",
   "metadata": {},
   "source": [
    "## スキャン処理 (Sequential Processing)\n",
    "\n",
    "時系列データの生成や状態更新を行うため、`scan_along_axis` を使用して時間軸（axis=1）に沿ったループ処理を行います。\n",
    "これは JAX の `jax.lax.scan` のラッパーであり、Python の `for` ループよりも高速にコンパイルされます。\n",
    "\n",
    "* **`f` (step function)**: 各ステップで実行される関数。`(carry, x) -> (new_carry, y)` の形式を取ります。\n",
    "* **`init`**: ループの初期状態（carryの初期値）。KVキャッシュの初期状態などが該当します。\n",
    "* **`xs`**: スキャン対象の入力シーケンス。\n",
    "* **`axis`**: ループを回す軸（ここでは時間軸 `1`）。\n",
    "\n",
    "以下の例では、仕組みを理解するために単純な「累積和（Cumulative Sum）」を計算しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d10f65b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (xs):\n",
      " [1. 1. 1. 1. 1.]\n",
      "Output (Cumulative Sum):\n",
      " [1. 2. 3. 4. 5.]\n",
      "Output Shape: (2, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from timesfm.flax.util import scan_along_axis\n",
    "\n",
    "# 1. ステップ関数の定義\n",
    "# 実際のTimesFMでは、ここはモデルの推論ステップ (decode_step) になります\n",
    "def mock_step_fn(carry, x):\n",
    "    \"\"\"\n",
    "    carry: 前のステップから持ち越された状態 (例: 累積値, KV Cache)\n",
    "    x: 現在のステップの入力\n",
    "    \"\"\"\n",
    "    new_carry = carry + x       # 状態の更新 (ここでは累積和)\n",
    "    output = new_carry * 1.0    # 現在のステップの出力\n",
    "    return new_carry, output\n",
    "\n",
    "# 2. ダミーデータの準備\n",
    "# [Batch, Time, Feature]\n",
    "B, T, D = 2, 5, 1\n",
    "xs_dummy = jnp.ones((B, T, D), dtype=jnp.float32)  # 入力: 全て1\n",
    "init_state = jnp.zeros((B, D), dtype=jnp.float32)  # 初期状態: 0\n",
    "\n",
    "# 3. scan_along_axis の実行\n",
    "# TODO の箇所を埋めています\n",
    "scan_result = scan_along_axis(\n",
    "    f=mock_step_fn,      # 各ステップで実行する関数\n",
    "    init=init_state,     # 初期状態 (carry)\n",
    "    xs=xs_dummy,         # 入力シーケンス\n",
    "    axis=1,              # 時間軸に沿ってスキャン\n",
    "    # kwargs={}            # step_fn に渡す追加引数があれば辞書で指定\n",
    ")\n",
    "\n",
    "# scan_along_axis の戻り値は (final_carry, stacked_outputs)\n",
    "final_state, outputs = scan_result\n",
    "\n",
    "print(\"Input (xs):\\n\", xs_dummy[0, :, 0])\n",
    "print(\"Output (Cumulative Sum):\\n\", outputs[0, :, 0])\n",
    "print(f\"Output Shape: {outputs.shape}\") # (2, 5, 1) - 入力と同じ形状が保たれる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfc79d8",
   "metadata": {},
   "source": [
    "## 統計量更新ロジックの修正\n",
    "\n",
    "`update_running_stats`関数の戻り値が2つ（`new_mu`, `new_sigma`）である場合に、3つの変数でのアンパッキングを行おうとして`ValueError`が発生していました。\n",
    "これに対処するため、戻り値の要素数を確認し、2つの場合は`new_n`（サンプル数）をマスクの和から手動で更新するように修正します。これにより、ライブラリの仕様変更や実装の差異に柔軟に対応します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27fd1ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Stats Update ---\n",
      "Count: [10. 10.] -> [[14. 14.]\n",
      " [14. 14.]]\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 修正版: 統計量の更新処理\n",
    "# File: /mnt/e/env/ts/lib_ana/src/model/timesfm/nb/timesfmV6.ipynb\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# マスクの作成 (Batch, P)\n",
    "mask_new = jnp.ones((B, P), dtype=jnp.bool_)\n",
    "\n",
    "# 3. 統計量の更新\n",
    "# 戻り値の数を確認してアンパッキングを行う\n",
    "# 通常は (new_n, new_mu, new_sigma) だが、実装により (new_mu, new_sigma) の場合があるため分岐処理を追加\n",
    "\n",
    "stats_result = update_running_stats(\n",
    "    n=n_current,\n",
    "    mu=mu_current,\n",
    "    sigma=sigma_current,\n",
    "    x=x_new,\n",
    "    mask=mask_new,\n",
    ")\n",
    "\n",
    "if len(stats_result) == 3:\n",
    "    # 期待通り3つの値が返された場合\n",
    "    new_n, new_mu, new_sigma = stats_result\n",
    "elif len(stats_result) == 2:\n",
    "    # 2つの値（mu, sigma）のみが返された場合\n",
    "    new_mu, new_sigma = stats_result\n",
    "    \n",
    "    # new_n を手動で更新\n",
    "    # マスクされている有効なデータ数を現在のカウントに加算\n",
    "    # axisはデータの次元に合わせて調整（ここでは最終次元の和を想定）\n",
    "    increment = jnp.sum(mask_new, axis=-1, keepdims=True)\n",
    "    new_n = n_current + increment\n",
    "else:\n",
    "    raise ValueError(f\"Unexpected return values from update_running_stats: expected 2 or 3, got {len(stats_result)}\")\n",
    "\n",
    "print(\"--- Stats Update ---\")\n",
    "print(f\"Count: {n_current} -> {new_n}\")\n",
    "# 必要であれば形状や値の確認\n",
    "# print(f\"Mu shape: {new_mu.shape}, Sigma shape: {new_sigma.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095e30ff",
   "metadata": {},
   "source": [
    "## 欠損データの線形補間 (Linear Interpolation)\n",
    "\n",
    "時系列データに含まれる欠損値（`NaN`: Not a Number / 非数）に対し、**線形補間 (Linear Interpolation)** を適用して値を充填します。\n",
    "\n",
    "### 1. 処理の目的 (Purpose)\n",
    "多くの時系列予測モデルは、入力データが連続していることを前提としており、欠損値が含まれていると計算エラー（`NaN`の伝播）や精度の低下を引き起こします。本処理により、データの完全性（Integrity）と連続性を確保します。\n",
    "\n",
    "### 2. アルゴリズムの仕組み (Mechanism)\n",
    "線形補間とは、グラフ上でデータが存在する2つの点（欠損の直前と直後）を定規で結ぶように直線を引き、その直線上にある値を推測値として採用する手法です。\n",
    "* **特徴**: 単純かつ計算コストが低い一方で、データの急激な変動には追従しにくい特性があります。しかし、一般的なトレンド（傾向）を維持する上では堅実な手法です。\n",
    "\n",
    "### 3. 実装上の注意 (Implementation Note)\n",
    "* **`arr` (Array / 配列)**: 補間対象の入力データです。`TODO` 部分には、欠損を含む具体的な変数（例: `context_data` や `ts_array` など）を指定してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59bf5c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Linear Interpolation Result ---\n",
      "Original shape: (2, 4)\n",
      "Interpolated shape: (2, 4)\n",
      "NaN count (Before): 0\n",
      "NaN count (After) : 0\n",
      "Success: All missing values have been interpolated.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 欠損値補間の実行\n",
    "# File: /mnt/e/env/ts/lib_ana/src/model/timesfm/nb/timesfmV6.ipynb\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from timesfm.timesfm_2p5.timesfm_2p5_base import linear_interpolation\n",
    "\n",
    "# 補間対象のデータを定義\n",
    "# NOTE: 前のセルで生成された 'x_new' (または処理したい時系列配列) を指定してください\n",
    "# 文脈に基づき、ここでは 'x_new' を対象とします\n",
    "target_array = x_new \n",
    "\n",
    "# 線形補間 (Linear Interpolation) の実行\n",
    "# arr: 欠損値(NaN)を含む可能性のある入力配列\n",
    "result_interpolated = linear_interpolation(\n",
    "    arr=target_array\n",
    ")\n",
    "\n",
    "# --- 結果の確認 (Meta-check) ---\n",
    "print(\"--- Linear Interpolation Result ---\")\n",
    "print(f\"Original shape: {target_array.shape}\")\n",
    "print(f\"Interpolated shape: {result_interpolated.shape}\")\n",
    "\n",
    "# 補間前後のNaN数を確認し、処理の有効性(Integrity)を検証\n",
    "original_nans = jnp.isnan(target_array).sum()\n",
    "remaining_nans = jnp.isnan(result_interpolated).sum()\n",
    "\n",
    "print(f\"NaN count (Before): {original_nans}\")\n",
    "print(f\"NaN count (After) : {remaining_nans}\")\n",
    "\n",
    "if remaining_nans == 0:\n",
    "    print(\"Success: All missing values have been interpolated.\")\n",
    "else:\n",
    "    print(\"Warning: Some NaN values remain (likely at the edges of the series).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c000f72",
   "metadata": {},
   "source": [
    "## 先頭欠損値の除去 (Stripping Leading NaNs)\n",
    "\n",
    "時系列配列の先頭（開始部分）に連続して存在する **NaN (Not a Number / 非数)** を除去、またはトリミングする処理を行います。\n",
    "\n",
    "### 1. 処理の目的 (Purpose)\n",
    "* **有効データの抽出 (Extraction):** 多くの時系列データでは、実際の計測が始まるまでの期間が `NaN` として埋められている場合があります。線形補間（Linear Interpolation）では「前後の値」が必要なため、この先頭の `NaN` は補間されずに残ることがあります。\n",
    "* **モデルの安定化 (Stabilization):** 学習や推論において、無意味な `NaN` 列を入力することは、計算エラーや勾配（Gradient）の消失・爆発を引き起こす要因となります。有効な数値が始まる時点をデータの「開始」と定義し直すことで、モデルの挙動を安定させます。\n",
    "\n",
    "### 2. アルゴリズムの仕組み (Mechanism)\n",
    "配列の先頭（インデックス0）から順に値をスキャンし、**最初の有効な数値 (Valid Number)** が現れる位置を特定します。その位置より前のデータを切り捨てるか、無視するマスク（Mask）を生成します。\n",
    "* ※実装によっては、配列自体の長さを短縮する場合と、パディング（Padding）として処理する場合の2パターンがありますが、本関数はライブラリの仕様に従い適切な形式（通常はトリミング後の配列）を返します。\n",
    "\n",
    "### 3. 実装上の注意 (Implementation Note)\n",
    "* **`arr`**: 処理対象の配列です。前のステップで線形補間を行った結果（例: `result_interpolated`）を入力することが一般的です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ceb769f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Strip Leading NaNs Result ---\n",
      "Original shape: (2, 4)\n",
      "Stripped shape: (2, 4)\n",
      "First value of first batch: 1.0\n",
      "Success: The series now starts with a valid number.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 先頭の欠損値(NaN)除去の実行\n",
    "# File: /mnt/e/env/ts/lib_ana/src/model/timesfm/nb/timesfmV6.ipynb\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from timesfm.timesfm_2p5.timesfm_2p5_base import strip_leading_nans\n",
    "\n",
    "# 処理対象のデータを定義\n",
    "# NOTE: 前のステップ（線形補間など）の結果変数を指定してください。\n",
    "# ここでは文脈に基づき 'result_interpolated' を対象とします。\n",
    "# もし補間を行っていない場合は元の 'x_new' などを指定します。\n",
    "input_array = result_interpolated \n",
    "\n",
    "# 先頭のNaNを除去 (Strip Leading NaNs)\n",
    "result_stripped = strip_leading_nans(\n",
    "    arr=input_array\n",
    ")\n",
    "\n",
    "# --- 結果の確認 (Meta-check) ---\n",
    "print(\"--- Strip Leading NaNs Result ---\")\n",
    "print(f\"Original shape: {input_array.shape}\")\n",
    "print(f\"Stripped shape: {result_stripped.shape}\")\n",
    "\n",
    "# 先頭の値を確認（有効な数値で始まっているか）\n",
    "# ※多次元配列の場合は最初のバッチを表示\n",
    "if result_stripped.ndim > 1:\n",
    "    first_val = result_stripped[0, 0]\n",
    "    print(f\"First value of first batch: {first_val}\")\n",
    "else:\n",
    "    first_val = result_stripped[0]\n",
    "    print(f\"First value: {first_val}\")\n",
    "\n",
    "# 検証 (Verification)\n",
    "if not jnp.isnan(first_val):\n",
    "    print(\"Success: The series now starts with a valid number.\")\n",
    "else:\n",
    "    print(\"Warning: The series still starts with NaN (Possible all-NaN series).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7dceba",
   "metadata": {},
   "source": [
    "## Transformer層の適用 (Applying Stacked Transformers)\n",
    "\n",
    "ロードした時系列データに対し、Transformerの主要部分（Attention層とFeedForward層の積み重ね）を適用する準備を行います。\n",
    "\n",
    "### 1. データ整形プロセス (Data Preparation)\n",
    "データベースから取得した `df` は「ロング形式（縦持ち）」です。これをモデル入力用に以下の手順で変換します。\n",
    "1.  **ピボット (Pivot):** `loto`, `ts_type` をインデックス、`ds` をカラムとして展開し、`(Batch, Sequence)` の形状にします。\n",
    "2.  **埋め込みシミュレーション (Embedding Simulation):** `_apply_stacked_transformers` は、次元 $D$ (Model Dimension) を持つ入力を期待します。ここでは実際のPatch Embeddingの代わりに、次元を拡張して入力をエミュレートします。\n",
    "\n",
    "[Image of Transformer model architecture input embedding]\n",
    "\n",
    "### 2. 引数の定義 (Arguments)\n",
    "* **`x`**: 入力テンソル。形状は `(Batch, Sequence, Model_Dim)` です。\n",
    "* **`m`**: マスク。パディング部分（データがない部分）を無視するために使用します。今回はすべて有効データとして `1` で埋めます。\n",
    "* **`model`**: 本来は学習済みのFlaxモジュールですが、ここでは動作確認用にダミー（Mock）を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12069f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivoted Data Shape: (36, 7366)\n",
      "--- Applying Stacked Transformers (Mock) ---\n",
      "Simulation skipped due to missing model structure: Expected an array, got MagicMock args[0]\n",
      "Fallback: Returned input as result for data flow check.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# データ整形とTransformer適用のエミュレーション\n",
    "# File: /mnt/e/env/ts/lib_ana/src/model/timesfm/nb/timesfmV6.ipynb\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import pandas as pd\n",
    "from unittest.mock import MagicMock\n",
    "from timesfm.timesfm_2p5.timesfm_2p5_flax import _apply_stacked_transformers\n",
    "\n",
    "# --- 1. DBデータの整形 (Preprocessing) ---\n",
    "# ロング形式のDFを (Batch, Time) に変換\n",
    "if 'df' in locals() and not df.empty:\n",
    "    # ユニークなIDごとに時系列を横に並べる\n",
    "    pivot_df = df.pivot_table(index=['loto', 'ts_type'], columns='ds', values='y')\n",
    "    # 欠損がある場合は0埋めなどを行う（必要に応じて変更）\n",
    "    pivot_df = pivot_df.fillna(0)\n",
    "    \n",
    "    raw_array = jnp.array(pivot_df.values) # Shape: (Batch, Sequence)\n",
    "    print(f\"Pivoted Data Shape: {raw_array.shape}\")\n",
    "else:\n",
    "    # データがない場合のフォールバック\n",
    "    raw_array = jnp.zeros((2, 32))\n",
    "\n",
    "# --- 2. 変数の準備 (Preparation) ---\n",
    "B, N = raw_array.shape\n",
    "D = 64  # Model Dimension (本来はモデル設定に依存。例: 512, 1024など)\n",
    "\n",
    "# x: 入力埋め込み (Input Embeddings)\n",
    "# 注意: Transformer層への入力は (Batch, Sequence, Model_Dim) である必要があります。\n",
    "# 実際のパイプラインでは PatchEmbedding 層の出力を使いますが、\n",
    "# ここでは raw_array を線形射影して擬似的に作成します。\n",
    "key = jax.random.PRNGKey(42)\n",
    "projection_matrix = jax.random.normal(key, (1, D)) # (1, D)\n",
    "# (B, N, 1) * (1, D) -> (B, N, D) へのブロードキャスト的な擬似拡張\n",
    "x_input = raw_array[..., None] * projection_matrix \n",
    "\n",
    "# m: アテンションマスク (Mask)\n",
    "# すべて有効なデータと仮定して 1.0 (float) または True (bool) を設定\n",
    "# 実装により型が異なりますが、JAXでは通常 float のマスク(1.0 keep, 0.0 drop)を使うことが多いです\n",
    "m_input = jnp.ones((B, N), dtype=jnp.float32)\n",
    "\n",
    "# model: Transformerモデル (Mock)\n",
    "# 内部で model.layers などを参照するため、ダミーオブジェクトを作成\n",
    "# ※実際に計算させるには本物のFlax Moduleが必要ですが、ここではエラー回避のためのMockです\n",
    "mock_model = MagicMock()\n",
    "mock_model.layers = [] # レイヤーリストを空にしておけばループが回らずそのまま出力される想定\n",
    "\n",
    "# --- 3. 関数の実行 (Execution) ---\n",
    "print(\"--- Applying Stacked Transformers (Mock) ---\")\n",
    "try:\n",
    "    result = _apply_stacked_transformers(\n",
    "        model=mock_model, # TODO: 本来は学習済みTransformerモデルインスタンス\n",
    "        x=x_input,        # TODO: Float[Array, 'b n d']\n",
    "        m=m_input,        # TODO: Float[Array, 'b n']\n",
    "        decode_cache=None,\n",
    "    )\n",
    "    \n",
    "    print(\"Success!\")\n",
    "    print(f\"Input shape: {x_input.shape}\")\n",
    "    print(f\"Output shape: {result.shape}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Simulation skipped due to missing model structure: {e}\")\n",
    "    # 実際のモデルがないと内部処理でエラーになる可能性が高いため、\n",
    "    # その場合は入力をそのまま出力とするパススルーを提示\n",
    "    result = x_input\n",
    "    print(\"Fallback: Returned input as result for data flow check.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693bbad0",
   "metadata": {},
   "source": [
    "## モデル入力前の正規化と前処理 (Pre-Model Decode Processing)\n",
    "\n",
    "生の時系列データ（Raw Input）をモデルが処理しやすい形式に変換します。具体的には、各入力ウィンドウに対して平均 $\\mu$ と標準偏差 $\\sigma$ を計算し、正規化（Standardization）を行います。\n",
    "\n",
    "### 1. 処理の目的 (Purpose)\n",
    "* **スケール不変性 (Scale Invariance):** 株価（数万円）と気温（数十度）のようにスケールが異なるデータでも、モデルが同様にパターンを学習できるようにします。\n",
    "* **数値安定性 (Numerical Stability):** データを $\\mu=0, \\sigma=1$ 近傍に分布させることで、勾配消失や発散を防ぎます。\n",
    "* **統計量の保持 (Statistics Retention):** 計算された $\\mu$ と $\\sigma$ は、推論後の「非正規化（Denormalization）」ステップで使用するため、ここで保持します。\n",
    "\n",
    "[Image of time series normalization process]\n",
    "\n",
    "### 2. 引数の定義 (Arguments)\n",
    "* **`fc` (Forecast Context):** 予測設定やハイパーパラメータを保持するコンテキストオブジェクト。\n",
    "* **`inputs`**: モデルへの入力時系列データ $(Batch, Time)$。\n",
    "* **`masks`**: パディングマスク（有効なデータ＝1、無効＝0）。欠損値や系列長の不足部分を無視させるために使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4fa210d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pre-Model Decode Processing (v3) ---\n",
      "AttributeError: 'MockFC' object has no attribute 'per_core_batch_size'\n",
      "Hint: If another attribute is missing, add it to the MockFC namedtuple.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 修正版(v3): 属性を追加したコンテキストによる前処理の実行\n",
    "# File: /mnt/e/env/ts/lib_ana/src/model/timesfm/nb/timesfmV6.ipynb\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from collections import namedtuple\n",
    "from timesfm.timesfm_2p5.timesfm_2p5_flax import _before_model_decode\n",
    "\n",
    "# --- 1. 入力データの準備 ---\n",
    "if 'raw_array' in locals():\n",
    "    input_tensor = raw_array\n",
    "else:\n",
    "    # Batch=2, Time=32 のダミー\n",
    "    input_tensor = jnp.array([\n",
    "        jnp.sin(jnp.linspace(0, 10, 32)) + 5,\n",
    "        jnp.cos(jnp.linspace(0, 10, 32)) * 10\n",
    "    ])\n",
    "\n",
    "# マスクの作成\n",
    "input_masks = jnp.ones_like(input_tensor, dtype=jnp.float32)\n",
    "\n",
    "# --- 2. コンテキストの作成 (属性追加) ---\n",
    "# エラーで指摘された 'normalize_inputs' をフィールドに追加します。\n",
    "MockFC = namedtuple(\"MockFC\", [\n",
    "    \"infer_is_positive\", \n",
    "    \"normalize_inputs\"   # 追加: 正規化を実行するかどうかのフラグ\n",
    "])\n",
    "\n",
    "# インスタンス化\n",
    "mock_fc = MockFC(\n",
    "    infer_is_positive=True,  # 非負値の推論: On\n",
    "    normalize_inputs=True    # 正規化処理: On\n",
    ")\n",
    "\n",
    "# --- 3. 前処理の実行 ---\n",
    "print(\"--- Pre-Model Decode Processing (v3) ---\")\n",
    "\n",
    "try:\n",
    "    # JAX jitコンパイル\n",
    "    result_tuple = _before_model_decode(\n",
    "        fc=mock_fc,          \n",
    "        inputs=input_tensor,\n",
    "        masks=input_masks\n",
    "    )\n",
    "\n",
    "    # --- 結果の確認 ---\n",
    "    # 戻り値の構成: (normalized_inputs, mu, sigma, is_positive)\n",
    "    if isinstance(result_tuple, tuple):\n",
    "        print(f\"Result Tuple Length: {len(result_tuple)}\")\n",
    "        \n",
    "        # 1. 正規化された入力\n",
    "        norm_inputs = result_tuple[0]\n",
    "        print(f\"Normalized Input Shape: {norm_inputs.shape}\")\n",
    "        \n",
    "        # 2. 統計量 (mu, sigma)\n",
    "        if len(result_tuple) >= 3:\n",
    "            mu = result_tuple[1]\n",
    "            sigma = result_tuple[2]\n",
    "            print(f\"Mu (Mean) Shape: {mu.shape}\")\n",
    "            print(f\"Sigma (Std) Shape: {sigma.shape}\")\n",
    "            \n",
    "            # 検証: 正規化後の平均は0、分散は1に近い値になるはず\n",
    "            print(f\"Mean (norm): {jnp.mean(norm_inputs):.4f}\")\n",
    "            print(f\"Std  (norm): {jnp.std(norm_inputs):.4f}\")\n",
    "            \n",
    "        # 3. 正値フラグ (is_positive)\n",
    "        if len(result_tuple) >= 4:\n",
    "            is_pos = result_tuple[3]\n",
    "            print(f\"Is Positive Flag Shape: {is_pos.shape}\")\n",
    "            print(f\"Is Positive (Example): {is_pos[0]}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Result Type: {type(result_tuple)}\")\n",
    "\n",
    "except AttributeError as e:\n",
    "    print(f\"AttributeError: {e}\")\n",
    "    print(\"Hint: If another attribute is missing, add it to the MockFC namedtuple.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777818e2",
   "metadata": {},
   "source": [
    "## Stacked Transformersの構築と初期化 (Model Initialization)\n",
    "\n",
    "設定オブジェクト (`config`) に基づき、多層Transformerモデルの構造を定義し、そのパラメータを初期化します。\n",
    "\n",
    "### 1. 処理の目的 (Purpose)\n",
    "* **アーキテクチャの定義:** 層の数（Layers）、ヘッドの数（Heads）、モデルの次元（Hidden Dimension）など、ニューラルネットワークの形状を決定します。\n",
    "* **パラメータ初期化 (Initialization):** 乱数キー (`key`) を使用して、重み（Weights）とバイアス（Biases）に初期値を割り当てます。JAX/Flaxでは、このステップでモデルの変数が確定します。\n",
    "\n",
    "[Image of Transformer architecture stack]\n",
    "\n",
    "### 2. 引数の定義 (Arguments)\n",
    "* **`config`**: モデルのハイパーパラメータを保持する設定オブジェクト。`StackedTransformersConfig` クラス（またはそれに準ずる構造体）のインスタンスが必要です。\n",
    "* **`key`**: JAXの乱数生成キー (`PRNGKey`)。再現可能な初期化のために使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60f9edee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating Stacked Transformers ---\n",
      "AttributeError: 'MockTransformerConfig' object has no attribute 'transformer'\n",
      "Hint: Check if 'config' structure matches the library expectation.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Transformerモデルの構築と初期化\n",
    "# File: /mnt/e/env/ts/lib_ana/src/model/timesfm/nb/timesfmV6.ipynb\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from collections import namedtuple\n",
    "from timesfm.timesfm_2p5.timesfm_2p5_flax import _create_stacked_transformers\n",
    "\n",
    "# --- 1. 設定オブジェクトの作成 (Mock Config) ---\n",
    "# 本来は configs.StackedTransformersConfig を使用しますが、\n",
    "# 動作確認用に必要な属性を持つ namedtuple (不変・ハッシュ可能) を定義します。\n",
    "MockTransformerConfig = namedtuple(\"MockTransformerConfig\", [\n",
    "    \"num_layers\",       # レイヤー数 (L)\n",
    "    \"model_dim\",        # モデル次元 (D)\n",
    "    \"num_heads\",        # 注意機構のヘッド数 (H)\n",
    "    \"dropout_rate\",     # ドロップアウト率\n",
    "    \"use_qkv_bias\",     # QKV射影にバイアスを使用するか\n",
    "    \"intermediate_dim\", # FeedForward層の中間次元\n",
    "    \"activation\",       # 活性化関数\n",
    "    \"norm_eps\"          # LayerNormのイプシロン\n",
    "])\n",
    "\n",
    "# 一般的な「Tiny」サイズの設定で初期化\n",
    "config_mock = MockTransformerConfig(\n",
    "    num_layers=2,\n",
    "    model_dim=64,\n",
    "    num_heads=4,\n",
    "    dropout_rate=0.1,\n",
    "    use_qkv_bias=False,\n",
    "    intermediate_dim=128,\n",
    "    activation=\"gelu\",\n",
    "    norm_eps=1e-6\n",
    ")\n",
    "\n",
    "# --- 2. 乱数キーの生成 ---\n",
    "# 初期化用の乱数シード\n",
    "init_key = jax.random.PRNGKey(42)\n",
    "\n",
    "# --- 3. モデル構築関数の実行 ---\n",
    "print(\"--- Creating Stacked Transformers ---\")\n",
    "\n",
    "try:\n",
    "    # モデル構造の作成またはパラメータの初期化を行います\n",
    "    # resultは通常、初期化されたパラメータ(FrozenDict)やモデル定義が返されます\n",
    "    result = _create_stacked_transformers(\n",
    "        config=config_mock, # TODO: configs.StackedTransformersConfig\n",
    "        key=init_key        # TODO: jax.Array\n",
    "    )\n",
    "    \n",
    "    print(\"Success: Transformers initialized.\")\n",
    "    print(f\"Result Type: {type(result)}\")\n",
    "    \n",
    "    # もし結果がパラメータ辞書(FrozenDict)なら中身のキーを確認\n",
    "    if hasattr(result, 'keys'):\n",
    "        print(f\"Top-level keys: {result.keys()}\")\n",
    "\n",
    "except TypeError as e:\n",
    "    print(f\"TypeError: {e}\")\n",
    "    print(\"Hint: The mock config might be missing attributes required by the specific library version.\")\n",
    "except AttributeError as e:\n",
    "    print(f\"AttributeError: {e}\")\n",
    "    print(\"Hint: Check if 'config' structure matches the library expectation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeadce0",
   "metadata": {},
   "source": [
    "## 分位点交差の修正 (Fix Quantile Crossing)\n",
    "\n",
    "確率的予測（Probabilistic Forecasting）の結果において、分位点間の順序関係が逆転している箇所を修正します。\n",
    "\n",
    "### 1. 処理の目的 (Purpose)\n",
    "* **論理的整合性の保証:** 分位点予測では、定義上 $Q_{10} \\le Q_{50} \\le Q_{90}$ のような大小関係が成立していなければなりません。しかし、モデルが各分位点を独立に回帰する場合など、数値計算上でこの順序が崩れる（Crossing）ことがあります。\n",
    "* **分布の妥当性:** 逆転したままでは確率分布として解釈できないため、これを修正して有効な信頼区間を構築します。\n",
    "\n",
    "\n",
    "\n",
    "### 2. アルゴリズム (Algorithm)\n",
    "最も単純かつ効果的な方法は、各タイムステップごとに予測値を**昇順にソート（Sort）**することです。これにより、順序制約が強制的に満たされます。\n",
    "\n",
    "### 3. 引数の定義 (Arguments)\n",
    "* **`full_forecast`**: モデルが出力した予測値の配列。形状は通常 `(Batch, Horizon, Quantiles)` です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea02fba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Before Fix (Crossing Data) ---\n",
      "[[[0.9 0.5 0.1]\n",
      "  [0.2 0.8 0.5]]]\n",
      "\n",
      "--- After Fix (Sorted Data) ---\n",
      "[[[0.9 0.1 0.1]\n",
      "  [0.2 0.5 0.5]]]\n",
      "\n",
      "Warning: Quantiles are still crossing.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 分位点交差の修正処理\n",
    "# File: /mnt/e/env/ts/lib_ana/src/model/timesfm/nb/timesfmV6.ipynb\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from timesfm.timesfm_2p5.timesfm_2p5_flax import _fix_quantile_crossing_fn\n",
    "\n",
    "# --- 1. 入力データの準備 (Input Preparation) ---\n",
    "# テスト用に、分位点の順序が逆転している(交差している)データを作成します。\n",
    "# Shape: (Batch=1, Horizon=2, Quantiles=3)\n",
    "# 例: [高い値, 中間の値, 低い値] -> 本来は [低, 中, 高] であるべき\n",
    "input_forecast = jnp.array([\n",
    "    [\n",
    "        [0.9, 0.5, 0.1],  # ケース1: 完全逆転 (Crossing発生)\n",
    "        [0.2, 0.8, 0.5]   # ケース2: 部分的逆転\n",
    "    ]\n",
    "])\n",
    "\n",
    "print(\"--- Before Fix (Crossing Data) ---\")\n",
    "print(input_forecast)\n",
    "\n",
    "# --- 2. 修正関数の実行 (Execution) ---\n",
    "# NOTE: 前のステップで生成された予測結果がある場合はそれを使用してください\n",
    "# result_forecast = _fix_quantile_crossing_fn(full_forecast=final_forecast_result[1])\n",
    "\n",
    "result_fixed = _fix_quantile_crossing_fn(\n",
    "    full_forecast=input_forecast  # TODO: Float[Array, 'b p q']\n",
    ")\n",
    "\n",
    "# --- 3. 結果の確認 (Meta-check) ---\n",
    "print(\"\\n--- After Fix (Sorted Data) ---\")\n",
    "print(result_fixed)\n",
    "\n",
    "# 検証: ソートされているか確認\n",
    "is_sorted = (jnp.diff(result_fixed, axis=-1) >= 0).all()\n",
    "if is_sorted:\n",
    "    print(\"\\nSuccess: All quantiles are correctly sorted.\")\n",
    "else:\n",
    "    print(\"\\nWarning: Quantiles are still crossing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658a6433",
   "metadata": {},
   "source": [
    "## 分位点の反転処理 (Flipping Quantiles)\n",
    "\n",
    "反転入力（$-x$）に対するモデルの予測結果である分位点の順序を逆転させます。\n",
    "\n",
    "### 1. 処理の目的 (Purpose)\n",
    "* **反転アンサンブルの整合性:** TimesFMは精度向上のため、元の系列 $x$ と、符号を反転させた系列 $-x$ の両方を予測し、その結果を平均します。\n",
    "* **分位点の対応関係:** データの符号を反転すると、大小関係が逆転します。例えば、負のデータにおける「上位10%（0.9分位点）」は、元の正のデータにおける「下位10%（0.1分位点）」に相当します。\n",
    "    * 数式的には: $P(-Y \\le q) = \\tau \\iff P(Y \\ge -q) = \\tau \\iff P(Y \\le -q) = 1 - \\tau$\n",
    "    * つまり、反転データの $\\tau$ 分位点は、元データの $1-\\tau$ 分位点に対応します。\n",
    "\n",
    "[Image of probability distribution flip quantile]\n",
    "\n",
    "### 2. アルゴリズム (Algorithm)\n",
    "入力された分位点配列の**最後の次元（Quantile dimension）を逆順**に並べ替えます。\n",
    "例: `[0.1, 0.5, 0.9]` $\\rightarrow$ `[0.9, 0.5, 0.1]`\n",
    "\n",
    "### 3. 引数の定義 (Arguments)\n",
    "* **`x`**: 反転入力に対する予測分位点配列。形状は `(Batch, Horizon, Quantiles)` です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "319d4a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Before Flip Function ---\n",
      "Input Quantiles: [[[-10.  -5.  -1.]]]\n",
      "\n",
      "--- After Flip Function ---\n",
      "Result Quantiles: [[[-10.  -1.  -5.]]]\n",
      "\n",
      "Warning: Flip operation did not work as expected.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 分位点配列の反転実行\n",
    "# File: /mnt/e/env/ts/lib_ana/src/model/timesfm/nb/timesfmV6.ipynb\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from timesfm.timesfm_2p5.timesfm_2p5_flax import _flip_quantile_fn\n",
    "\n",
    "# --- 1. 入力データの準備 (Input Preparation) ---\n",
    "# 反転入力(-x)から得られた予測分位点と仮定します。\n",
    "# Shape: (Batch=1, Horizon=1, Quantiles=3)\n",
    "# 例: 負の世界での [10%点, 50%点, 90%点]\n",
    "flipped_quantiles_input = jnp.array([\n",
    "    [[ -10.0, -5.0, -1.0 ]] \n",
    "])\n",
    "\n",
    "print(\"--- Before Flip Function ---\")\n",
    "print(f\"Input Quantiles: {flipped_quantiles_input}\")\n",
    "\n",
    "# --- 2. 関数の実行 (Execution) ---\n",
    "# 配列の順序を反転させます (Reverse)\n",
    "result_flipped = _flip_quantile_fn(\n",
    "    x=flipped_quantiles_input  # TODO: Float[Array, '... q']\n",
    ")\n",
    "\n",
    "# --- 3. 結果の確認 (Meta-check) ---\n",
    "print(\"\\n--- After Flip Function ---\")\n",
    "print(f\"Result Quantiles: {result_flipped}\")\n",
    "\n",
    "# 検証: 最初の要素が最後の要素に入れ替わっているか\n",
    "input_first = flipped_quantiles_input[..., 0]\n",
    "result_last = result_flipped[..., -1]\n",
    "\n",
    "if jnp.allclose(input_first, result_last):\n",
    "    print(\"\\nSuccess: Quantile order has been correctly reversed.\")\n",
    "    print(\"Explanation: The 10% quantile of -X corresponds to the 90% quantile of X.\")\n",
    "else:\n",
    "    print(\"\\nWarning: Flip operation did not work as expected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f61ff3c",
   "metadata": {},
   "source": [
    "## 反転不変性の適用 (Forcing Flip Invariance)\n",
    "\n",
    "符号を反転させた入力データ（$-x$）から得られたモデル出力に対し、再度符号反転（$-1$ を掛ける）を行い、元のデータ空間（$x$）と整合する値に戻します。\n",
    "\n",
    "### 1. 処理の目的 (Purpose)\n",
    "* **二重否定による復元 (Double Negation):** TimesFMの反転アンサンブル戦略では、以下のロジックで予測を統合します。\n",
    "    1.  **入力反転:** $x \\rightarrow -x$\n",
    "    2.  **推論:** $M(-x) \\approx -y$ （モデルは「反転した世界」での未来を予測する）\n",
    "    3.  **出力反転:** $-(-y) = y$ （予測値を元の世界に戻す）\n",
    "* **不変性の保証:** この処理により、モデルが「入力の符号が変われば、出力の符号も変わる」という物理的な対称性を満たすことを強制します。\n",
    "\n",
    "[Image of negative sign inversion math concept]\n",
    "\n",
    "### 2. 引数の定義 (Arguments)\n",
    "すべての引数は、反転入力（$-x$）に対するモデルの生出力です。\n",
    "* **`flipped_pf_outputs`**: 点予測値（Point Forecasts）。\n",
    "* **`flipped_quantile_spreads`**: 分位点の広がり（Spreads）。※実装により、値そのものか広がりかの定義が異なりますが、ここでは符号反転が必要な成分として扱います。\n",
    "* **`flipped_ar_outputs`**: 自己回帰成分（Auto-Regressive Outputs）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cda48ab6",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Too many indices: array is 0-dimensional, but 1 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# 例: 生成（デコード）でキャッシュを使う場合のクエリ位置オフセット（ここでは0）\u001b[39;00m\n\u001b[32m     14\u001b[39m query_index_offset = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m attn_mask = \u001b[43mmake_attn_mask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_all_masked_kv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_all_masked_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_index_offset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_index_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkv_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkv_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(attn_mask.shape, attn_mask.dtype)\n",
      "    \u001b[31m[... skipping hidden 4 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ts/lib/python3.11/site-packages/timesfm/flax/transformer.py:59\u001b[39m, in \u001b[36mmake_attn_mask\u001b[39m\u001b[34m(query_length, num_all_masked_kv, query_index_offset, kv_length)\u001b[39m\n\u001b[32m     57\u001b[39m q_index = jnp.arange(query_length)[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, :, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m query_index_offset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m   q_index += \u001b[43mquery_index_offset\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\n\u001b[32m     60\u001b[39m kv_index = jnp.arange(kv_length)[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m jnp.logical_and(\n\u001b[32m     62\u001b[39m   q_index >= kv_index,\n\u001b[32m     63\u001b[39m   kv_index >= num_all_masked_kv[:, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m],\n\u001b[32m     64\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ts/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:1146\u001b[39m, in \u001b[36m_forward_operator_to_aval.<locals>.op\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mop\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args):\n\u001b[32m-> \u001b[39m\u001b[32m1146\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ts/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:683\u001b[39m, in \u001b[36m_getitem\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    682\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_getitem\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[32m--> \u001b[39m\u001b[32m683\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexing\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrewriting_take\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ts/lib/python3.11/site-packages/jax/_src/numpy/indexing.py:1188\u001b[39m, in \u001b[36mrewriting_take\u001b[39m\u001b[34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value, normalize_indices, out_sharding, strategy)\u001b[39m\n\u001b[32m   1174\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrewriting_take\u001b[39m(\n\u001b[32m   1175\u001b[39m     arr: Array,\n\u001b[32m   1176\u001b[39m     idx: Index | \u001b[38;5;28mtuple\u001b[39m[Index, ...], *,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1186\u001b[39m   \u001b[38;5;66;03m# All supported cases of indexing can be implemented as an XLA gather,\u001b[39;00m\n\u001b[32m   1187\u001b[39m   \u001b[38;5;66;03m# followed by an optional reverse and broadcast_in_dim.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1188\u001b[39m   indexer = \u001b[43mNDIndexer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_raw_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1190\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(strategy, IndexingStrategy):\n\u001b[32m   1191\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected strategy to be IndexingStrategy; got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstrategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ts/lib/python3.11/site-packages/jax/_src/numpy/indexing.py:197\u001b[39m, in \u001b[36mNDIndexer.from_raw_indices\u001b[39m\u001b[34m(cls, indices, shape)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create an NDIndexer object from raw user-supplied indices.\"\"\"\u001b[39;00m\n\u001b[32m    196\u001b[39m indices = eliminate_deprecated_list_indexing(indices)\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m indices = \u001b[43m_parse_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(shape=shape, indices=indices)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ts/lib/python3.11/site-packages/jax/_src/numpy/indexing.py:163\u001b[39m, in \u001b[36m_parse_indices\u001b[39m\u001b[34m(indices, shape)\u001b[39m\n\u001b[32m    161\u001b[39m total_consumed = \u001b[38;5;28msum\u001b[39m(dimensions_consumed)\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m total_consumed > \u001b[38;5;28mlen\u001b[39m(shape):\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mToo many indices: array is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-dimensional,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    164\u001b[39m                    \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_consumed\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m were indexed\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ellipses_indices:\n\u001b[32m    166\u001b[39m   dimensions_consumed[ellipses_indices[\u001b[32m0\u001b[39m]] = \u001b[38;5;28mlen\u001b[39m(shape) - total_consumed\n",
      "\u001b[31mIndexError\u001b[39m: Too many indices: array is 0-dimensional, but 1 were indexed"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "from timesfm.flax.transformer import make_attn_mask\n",
    "\n",
    "# 例: バッチ2、クエリ長128、KV長128（自己注意）を想定\n",
    "b = 2\n",
    "query_length = 128\n",
    "kv_length = 128\n",
    "\n",
    "# 例: 左パディング等で「先頭から何個のKVトークンを完全に無効化するか」\n",
    "#   バッチ0は0個、バッチ1は10個ぶんを完全マスク\n",
    "num_all_masked_kv = jnp.array([0, 10], dtype=jnp.int32)\n",
    "\n",
    "# 例: 生成（デコード）でキャッシュを使う場合のクエリ位置オフセット（ここでは0）\n",
    "query_index_offset = 0\n",
    "\n",
    "attn_mask = make_attn_mask(\n",
    "    query_length=query_length,\n",
    "    num_all_masked_kv=num_all_masked_kv,\n",
    "    query_index_offset=query_index_offset,\n",
    "    kv_length=kv_length,\n",
    ")\n",
    "\n",
    "print(attn_mask.shape, attn_mask.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6d7d2a",
   "metadata": {},
   "source": [
    "### `revin`（RevIN: Reversible Instance Normalization / 可逆インスタンス正規化）\n",
    "`x` を平均 `mu` と標準偏差 `sigma` で正規化（normalize）または逆変換（denormalize）します。\n",
    "\n",
    "- `reverse=False`：正規化（おおむね `(x - mu) / sigma`）\n",
    "- `reverse=True`：逆変換（おおむね `x * sigma + mu`）\n",
    "\n",
    "`mu` と `sigma` は通常、各系列（各サンプル）ごとに時系列方向などで計算した統計量を入れます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2231501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      " [[ 0.  1.  2.  3.  4.  5.  6.  7.]\n",
      " [ 8.  9. 10. 11. 12. 13. 14. 15.]]\n",
      "x_norm:\n",
      " [[-1.5275246  -1.091089   -0.6546534  -0.21821779  0.21821779  0.6546534\n",
      "   1.091089    1.5275246 ]\n",
      " [-1.5275246  -1.091089   -0.6546534  -0.21821779  0.21821779  0.6546534\n",
      "   1.091089    1.5275246 ]]\n",
      "reconstructed (should be close):\n",
      " [[-6.6407267e-08  9.9999994e-01  2.0000000e+00  3.0000000e+00\n",
      "   4.0000000e+00  5.0000000e+00  6.0000000e+00  7.0000000e+00]\n",
      " [ 8.0000000e+00  9.0000000e+00  1.0000000e+01  1.1000000e+01\n",
      "   1.2000000e+01  1.3000000e+01  1.4000000e+01  1.5000000e+01]]\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "from timesfm.flax.util import revin\n",
    "\n",
    "# 例: (batch, time) の時系列\n",
    "x = jnp.arange(2 * 8, dtype=jnp.float32).reshape(2, 8)\n",
    "\n",
    "# 例: 時間方向で平均・標準偏差（keepdims=Trueでブロードキャストしやすく）\n",
    "mu = x.mean(axis=-1, keepdims=True)\n",
    "sigma = x.std(axis=-1, keepdims=True) + 1e-6  # 0割り防止\n",
    "\n",
    "x_norm = revin(x=x, mu=mu, sigma=sigma, reverse=False)\n",
    "x_rec = revin(x=x_norm, mu=mu, sigma=sigma, reverse=True)\n",
    "\n",
    "print(\"x:\\n\", x)\n",
    "print(\"x_norm:\\n\", x_norm)\n",
    "print(\"reconstructed (should be close):\\n\", x_rec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60b484b",
   "metadata": {},
   "source": [
    "### `_force_flip_invariance_fn`（符号反転に対する整合性付与：推定）\n",
    "TimesFM-2.5 の内部処理で、入力系列の **符号反転（flip: x→-x）** に対して予測の整合性を保つための補正を行う関数…と推定されます。\n",
    "\n",
    "典型的には、\n",
    "- 点予測（point forecast）は符号が反転（-を掛ける）\n",
    "- 分位点の“広がり”（quantile spreads）は非負量なので反転せず、順序だけ入れ替える…等\n",
    "\n",
    "ただし、これは一般論であり、正確には `timesfm_2p5_flax.py` の実装を参照してください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1acaea5",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Too many indices: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m flipped_quantile_spreads = jnp.ones((b, horizon, num_q), dtype=jnp.float32)\n\u001b[32m     11\u001b[39m flipped_ar_outputs = jnp.zeros((b, horizon), dtype=jnp.float32)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m result = \u001b[43m_force_flip_invariance_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflipped_pf_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflipped_pf_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflipped_quantile_spreads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflipped_quantile_spreads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflipped_ar_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflipped_ar_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# 戻り値の型/構造は実装依存なので、まずはprintして確認\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(result))\n",
      "    \u001b[31m[... skipping hidden 4 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ts/lib/python3.11/site-packages/timesfm/timesfm_2p5/timesfm_2p5_flax.py:294\u001b[39m, in \u001b[36m_force_flip_invariance_fn\u001b[39m\u001b[34m(flipped_pf_outputs, flipped_quantile_spreads, flipped_ar_outputs)\u001b[39m\n\u001b[32m    292\u001b[39m flipped_quantile_spreads = _flip_quantile_fn(flipped_quantile_spreads)\n\u001b[32m    293\u001b[39m flipped_quantile_spreads = jax_einshape(\u001b[33m\"\u001b[39m\u001b[33mtb...->(tb)...\u001b[39m\u001b[33m\"\u001b[39m, flipped_quantile_spreads)\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m to_concat = [\u001b[43mflipped_pf_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m]\u001b[49m]\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m flipped_ar_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    296\u001b[39m   flipped_ar_outputs = _flip_quantile_fn(flipped_ar_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ts/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:1146\u001b[39m, in \u001b[36m_forward_operator_to_aval.<locals>.op\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mop\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args):\n\u001b[32m-> \u001b[39m\u001b[32m1146\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ts/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:683\u001b[39m, in \u001b[36m_getitem\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    682\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_getitem\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[32m--> \u001b[39m\u001b[32m683\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexing\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrewriting_take\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ts/lib/python3.11/site-packages/jax/_src/numpy/indexing.py:1188\u001b[39m, in \u001b[36mrewriting_take\u001b[39m\u001b[34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value, normalize_indices, out_sharding, strategy)\u001b[39m\n\u001b[32m   1174\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrewriting_take\u001b[39m(\n\u001b[32m   1175\u001b[39m     arr: Array,\n\u001b[32m   1176\u001b[39m     idx: Index | \u001b[38;5;28mtuple\u001b[39m[Index, ...], *,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1186\u001b[39m   \u001b[38;5;66;03m# All supported cases of indexing can be implemented as an XLA gather,\u001b[39;00m\n\u001b[32m   1187\u001b[39m   \u001b[38;5;66;03m# followed by an optional reverse and broadcast_in_dim.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1188\u001b[39m   indexer = \u001b[43mNDIndexer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_raw_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1190\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(strategy, IndexingStrategy):\n\u001b[32m   1191\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected strategy to be IndexingStrategy; got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstrategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ts/lib/python3.11/site-packages/jax/_src/numpy/indexing.py:197\u001b[39m, in \u001b[36mNDIndexer.from_raw_indices\u001b[39m\u001b[34m(cls, indices, shape)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create an NDIndexer object from raw user-supplied indices.\"\"\"\u001b[39;00m\n\u001b[32m    196\u001b[39m indices = eliminate_deprecated_list_indexing(indices)\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m indices = \u001b[43m_parse_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(shape=shape, indices=indices)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ts/lib/python3.11/site-packages/jax/_src/numpy/indexing.py:163\u001b[39m, in \u001b[36m_parse_indices\u001b[39m\u001b[34m(indices, shape)\u001b[39m\n\u001b[32m    161\u001b[39m total_consumed = \u001b[38;5;28msum\u001b[39m(dimensions_consumed)\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m total_consumed > \u001b[38;5;28mlen\u001b[39m(shape):\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mToo many indices: array is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-dimensional,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    164\u001b[39m                    \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_consumed\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m were indexed\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ellipses_indices:\n\u001b[32m    166\u001b[39m   dimensions_consumed[ellipses_indices[\u001b[32m0\u001b[39m]] = \u001b[38;5;28mlen\u001b[39m(shape) - total_consumed\n",
      "\u001b[31mIndexError\u001b[39m: Too many indices: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "from timesfm.timesfm_2p5.timesfm_2p5_flax import _force_flip_invariance_fn\n",
    "\n",
    "# ※形状は実装依存。ここでは「ありがちな」形を仮置きします。\n",
    "b = 2\n",
    "horizon = 128\n",
    "num_q = 9  # 例: 分位点関連の次元（仮）\n",
    "\n",
    "flipped_pf_outputs = jnp.zeros((b, horizon), dtype=jnp.float32)\n",
    "flipped_quantile_spreads = jnp.ones((b, horizon, num_q), dtype=jnp.float32)\n",
    "flipped_ar_outputs = jnp.zeros((b, horizon), dtype=jnp.float32)\n",
    "\n",
    "result = _force_flip_invariance_fn(\n",
    "    flipped_pf_outputs=flipped_pf_outputs,\n",
    "    flipped_quantile_spreads=flipped_quantile_spreads,\n",
    "    flipped_ar_outputs=flipped_ar_outputs,\n",
    ")\n",
    "\n",
    "# 戻り値の型/構造は実装依存なので、まずはprintして確認\n",
    "print(type(result))\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c025201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(query_length: int, num_all_masked_kv: jaxtyping.Integer[jaxlib._jax.Array, 'b'], query_index_offset: jaxtyping.Integer[jaxlib._jax.Array, 'b'] | None = None, kv_length: int = 0) -> jaxtyping.Bool[jaxlib._jax.Array, 'b 1 q n']\n",
      "@functools.partial(\n",
      "  jax.jit,\n",
      "  static_argnames=(\"query_length\", \"kv_length\"),\n",
      ")\n",
      "def make_attn_mask(\n",
      "  query_length: int,\n",
      "  num_all_masked_kv: Integer[Array, \"b\"],\n",
      "  query_index_offset: Integer[Array, \"b\"] | None = None,\n",
      "  kv_length: int = 0,\n",
      ") -> Bool[Array, \"b 1 q n\"]:\n",
      "  \"\"\"Makes attention mask.\"\"\"\n",
      "\n",
      "  if kv_length == 0:\n",
      "    kv_length = query_length\n",
      "\n",
      "  q_index = jnp.arange(query_length)[None, None, :, None]\n",
      "  if query_index_offset is not None:\n",
      "    q_index += query_index_offset[:, None, None, None]\n",
      "  kv_index = jnp.arange(kv_length)[None, None, None, :]\n",
      "  return jnp.logical_and(\n",
      "    q_index >= kv_index,\n",
      "    kv_index >= num_all_masked_kv[:, None, None, None],\n",
      "  )\n",
      "\n",
      "(x: jaxtyping.Float[jaxlib._jax.Array, 'b ...'], mu: jaxtyping.Float[jaxlib._jax.Array, 'b ...'], sigma: jaxtyping.Float[jaxlib._jax.Array, 'b ...'], reverse: bool = False)\n",
      "@functools.partial(jax.jit, static_argnames=(\"reverse\",))\n",
      "def revin(\n",
      "  x: Float[Array, \"b ...\"],\n",
      "  mu: Float[Array, \"b ...\"],\n",
      "  sigma: Float[Array, \"b ...\"],\n",
      "  reverse: bool = False,\n",
      "):\n",
      "  \"\"\"Reversible per-instance normalization.\"\"\"\n",
      "  if len(mu.shape) == len(x.shape) - 1:\n",
      "    mu = mu[..., None]\n",
      "    sigma = sigma[..., None]\n",
      "  elif len(mu.shape) == len(x.shape) - 2:\n",
      "    mu = mu[..., None, None]\n",
      "    sigma = sigma[..., None, None]\n",
      "  if reverse:\n",
      "    return x * sigma + mu\n",
      "  else:\n",
      "    return (x - mu) / jnp.where(sigma < _TOLERANCE, 1.0, sigma)\n",
      "\n",
      "(flipped_pf_outputs, flipped_quantile_spreads, flipped_ar_outputs)\n",
      "@functools.partial(\n",
      "  jax.jit,\n",
      "  donate_argnums=(0, 1, 2),\n",
      ")\n",
      "def _force_flip_invariance_fn(\n",
      "  flipped_pf_outputs,\n",
      "  flipped_quantile_spreads,\n",
      "  flipped_ar_outputs,\n",
      "):\n",
      "  \"\"\"Forces flip invariance.\"\"\"\n",
      "  flipped_pf_outputs = _flip_quantile_fn(flipped_pf_outputs)\n",
      "  flipped_pf_outputs = jax_einshape(\"tb...->(tb)...\", flipped_pf_outputs)\n",
      "  flipped_quantile_spreads = _flip_quantile_fn(flipped_quantile_spreads)\n",
      "  flipped_quantile_spreads = jax_einshape(\"tb...->(tb)...\", flipped_quantile_spreads)\n",
      "  to_concat = [flipped_pf_outputs[:, -1, ...]]\n",
      "  if flipped_ar_outputs is not None:\n",
      "    flipped_ar_outputs = _flip_quantile_fn(flipped_ar_outputs)\n",
      "    flipped_ar_outputs = jax_einshape(\"tbno...->(tb)(no)...\", flipped_ar_outputs)\n",
      "    to_concat.append(flipped_ar_outputs)\n",
      "  flipped_full_forecast = jnp.concatenate(to_concat, axis=1)\n",
      "\n",
      "  return flipped_quantile_spreads, flipped_pf_outputs, flipped_full_forecast\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from timesfm.flax.transformer import make_attn_mask\n",
    "from timesfm.flax.util import revin\n",
    "from timesfm.timesfm_2p5.timesfm_2p5_flax import _force_flip_invariance_fn\n",
    "\n",
    "print(inspect.signature(make_attn_mask))\n",
    "print(inspect.getsource(make_attn_mask))\n",
    "\n",
    "print(inspect.signature(revin))\n",
    "print(inspect.getsource(revin))\n",
    "\n",
    "print(inspect.signature(_force_flip_invariance_fn))\n",
    "print(inspect.getsource(_force_flip_invariance_fn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f565d1d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Too many indices: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# quantile_spreads: 平均から各分位点へのオフセット（10%〜90%で9本）を想定\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m#   典型: (b, max_horizon, 9)\u001b[39;00m\n\u001b[32m     17\u001b[39m quantile_spreads = jnp.zeros((b, max_horizon, \u001b[32m9\u001b[39m), dtype=jnp.float32)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m result = \u001b[43m_use_continuous_quantile_head_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfull_forecast\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfull_forecast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquantile_spreads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquantile_spreads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_horizon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_horizon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m result\n",
      "    \u001b[31m[... skipping hidden 4 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ts/lib/python3.11/site-packages/timesfm/timesfm_2p5/timesfm_2p5_flax.py:316\u001b[39m, in \u001b[36m_use_continuous_quantile_head_fn\u001b[39m\u001b[34m(full_forecast, quantile_spreads, max_horizon)\u001b[39m\n\u001b[32m    311\u001b[39m to_stack = [full_forecast[..., :max_horizon, \u001b[32m0\u001b[39m]]\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m quantile_index \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m]:\n\u001b[32m    313\u001b[39m   to_stack.append(\n\u001b[32m    314\u001b[39m     quantile_spreads[:, :max_horizon, quantile_index]\n\u001b[32m    315\u001b[39m     - quantile_spreads[:, :max_horizon, \u001b[32m5\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     + \u001b[43mfull_forecast\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mmax_horizon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    317\u001b[39m   )\n\u001b[32m    318\u001b[39m to_stack.append(full_forecast[..., :max_horizon, \u001b[32m5\u001b[39m])\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m quantile_index \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m6\u001b[39m, \u001b[32m7\u001b[39m, \u001b[32m8\u001b[39m, \u001b[32m9\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ts/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:1146\u001b[39m, in \u001b[36m_forward_operator_to_aval.<locals>.op\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mop\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args):\n\u001b[32m-> \u001b[39m\u001b[32m1146\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ts/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:683\u001b[39m, in \u001b[36m_getitem\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    682\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_getitem\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[32m--> \u001b[39m\u001b[32m683\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexing\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrewriting_take\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ts/lib/python3.11/site-packages/jax/_src/numpy/indexing.py:1188\u001b[39m, in \u001b[36mrewriting_take\u001b[39m\u001b[34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value, normalize_indices, out_sharding, strategy)\u001b[39m\n\u001b[32m   1174\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrewriting_take\u001b[39m(\n\u001b[32m   1175\u001b[39m     arr: Array,\n\u001b[32m   1176\u001b[39m     idx: Index | \u001b[38;5;28mtuple\u001b[39m[Index, ...], *,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1186\u001b[39m   \u001b[38;5;66;03m# All supported cases of indexing can be implemented as an XLA gather,\u001b[39;00m\n\u001b[32m   1187\u001b[39m   \u001b[38;5;66;03m# followed by an optional reverse and broadcast_in_dim.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1188\u001b[39m   indexer = \u001b[43mNDIndexer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_raw_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1190\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(strategy, IndexingStrategy):\n\u001b[32m   1191\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected strategy to be IndexingStrategy; got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstrategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ts/lib/python3.11/site-packages/jax/_src/numpy/indexing.py:197\u001b[39m, in \u001b[36mNDIndexer.from_raw_indices\u001b[39m\u001b[34m(cls, indices, shape)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create an NDIndexer object from raw user-supplied indices.\"\"\"\u001b[39;00m\n\u001b[32m    196\u001b[39m indices = eliminate_deprecated_list_indexing(indices)\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m indices = \u001b[43m_parse_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(shape=shape, indices=indices)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ts/lib/python3.11/site-packages/jax/_src/numpy/indexing.py:163\u001b[39m, in \u001b[36m_parse_indices\u001b[39m\u001b[34m(indices, shape)\u001b[39m\n\u001b[32m    161\u001b[39m total_consumed = \u001b[38;5;28msum\u001b[39m(dimensions_consumed)\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m total_consumed > \u001b[38;5;28mlen\u001b[39m(shape):\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mToo many indices: array is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-dimensional,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    164\u001b[39m                    \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_consumed\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m were indexed\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ellipses_indices:\n\u001b[32m    166\u001b[39m   dimensions_consumed[ellipses_indices[\u001b[32m0\u001b[39m]] = \u001b[38;5;28mlen\u001b[39m(shape) - total_consumed\n",
      "\u001b[31mIndexError\u001b[39m: Too many indices: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "# Auto-generated call stub (CLE V6)\n",
    "# NOTE: TODO を埋めた例（形状は README の出力例に合わせた“典型”）\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from timesfm.timesfm_2p5.timesfm_2p5_flax import _use_continuous_quantile_head_fn\n",
    "\n",
    "# 例: バッチサイズと最大予測長（horizon）\n",
    "b = 2\n",
    "max_horizon = 256\n",
    "\n",
    "# full_forecast: 点予測（平均/期待値に相当）を想定\n",
    "#   典型: (b, max_horizon)\n",
    "full_forecast = jnp.zeros((b, max_horizon), dtype=jnp.float32)\n",
    "\n",
    "# quantile_spreads: 平均から各分位点へのオフセット（10%〜90%で9本）を想定\n",
    "#   典型: (b, max_horizon, 9)\n",
    "quantile_spreads = jnp.zeros((b, max_horizon, 9), dtype=jnp.float32)\n",
    "\n",
    "result = _use_continuous_quantile_head_fn(\n",
    "    full_forecast=full_forecast,\n",
    "    quantile_spreads=quantile_spreads,\n",
    "    max_horizon=max_horizon,\n",
    ")\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6865258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-generated call stub (CLE V6)\n",
    "\n",
    "# NOTE: TODO のところを埋めてください\n",
    "\n",
    "from timesfm.timesfm_2p5.timesfm_2p5_flax import try_gc\n",
    "\n",
    "result = try_gc(\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a8d1f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TimesFM Config Setup Demo ===\n",
      "\n",
      "[ForecastConfig]\n",
      " Context: 512, Horizon: 128\n",
      "\n",
      "[RandomFourierFeaturesConfig]\n",
      " Input: 1 -> Output: 64\n",
      "\n",
      "[ResidualBlockConfig]\n",
      " Dims: 64 -> 1280 -> 1280\n",
      " Activation: swish\n",
      "\n",
      "[TransformerConfig (Single Layer)]\n",
      " Model Dims: 1280, Heads: 16\n",
      " Norm Type: rms, RoPE: True\n",
      "\n",
      "[StackedTransformersConfig]\n",
      " Total Layers: 20\n",
      " --> Configuration objects are ready for model initialization.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from timesfm.configs import (\n",
    "    ForecastConfig,\n",
    "    RandomFourierFeaturesConfig,\n",
    "    ResidualBlockConfig,\n",
    "    TransformerConfig,\n",
    "    StackedTransformersConfig\n",
    ")\n",
    "\n",
    "def run_config_demo():\n",
    "    print(\"=== TimesFM Config Setup Demo ===\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 1. ForecastConfig: 予測タスクの設定\n",
    "    # ---------------------------------------------------------\n",
    "    # コンテキスト長512, 予測ホライゾン128という一般的な設定\n",
    "    forecast_config = ForecastConfig(\n",
    "        max_context=512,\n",
    "        max_horizon=128,\n",
    "        normalize_inputs=True,\n",
    "        window_size=1024,  # context + horizon + margin\n",
    "        per_core_batch_size=32,\n",
    "        use_continuous_quantile_head=False,\n",
    "        force_flip_invariance=True,  # 上下反転した波形でも同じロジックが通用するようにする\n",
    "        infer_is_positive=False,     # 売上など負の値がないデータならTrue\n",
    "        fix_quantile_crossing=True,  # 分位点の順序逆転（50%値 > 90%値など）を防ぐ\n",
    "        return_backcast=False\n",
    "    )\n",
    "    print(f\"\\n[ForecastConfig]\\n Context: {forecast_config.max_context}, Horizon: {forecast_config.max_horizon}\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2. RandomFourierFeaturesConfig: RFF層の設定\n",
    "    # ---------------------------------------------------------\n",
    "    # 時系列の特徴抽出に使われるランダムフーリエ特徴量\n",
    "    rff_config = RandomFourierFeaturesConfig(\n",
    "        input_dims=1,           # 単変量時系列なら1\n",
    "        output_dims=64,         # 特徴空間への射影次元\n",
    "        projection_stddev=1.0,  # 重み初期化の標準偏差\n",
    "        use_bias=True\n",
    "    )\n",
    "    print(f\"\\n[RandomFourierFeaturesConfig]\\n Input: {rff_config.input_dims} -> Output: {rff_config.output_dims}\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 3. ResidualBlockConfig: 残差ブロックの設定\n",
    "    # ---------------------------------------------------------\n",
    "    # トークナイザーや出力層として使われるMLPブロック\n",
    "    res_block_config = ResidualBlockConfig(\n",
    "        input_dims=64,          # RFFの出力などを受け取る\n",
    "        hidden_dims=1280,       # モデル次元へ拡張\n",
    "        output_dims=1280,\n",
    "        use_bias=True,\n",
    "        activation='swish'      # Swish (SiLU) 活性化関数\n",
    "    )\n",
    "    print(f\"\\n[ResidualBlockConfig]\\n Dims: {res_block_config.input_dims} -> {res_block_config.hidden_dims} -> {res_block_config.output_dims}\")\n",
    "    print(f\" Activation: {res_block_config.activation}\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 4. TransformerConfig: 単一Transformer層の設定\n",
    "    # ---------------------------------------------------------\n",
    "    # TimesFM 2.5 200Mモデルに近い設定\n",
    "    # - RMSNorm採用\n",
    "    # - RoPE採用\n",
    "    # - Swish活性化関数\n",
    "    tf_layer_config = TransformerConfig(\n",
    "        model_dims=1280,\n",
    "        hidden_dims=1280,       # FFNの隠れ層サイズ\n",
    "        num_heads=16,           # 1280 / 16 = 80次元/ヘッド\n",
    "        attention_norm='rms',   # RMSNorm\n",
    "        feedforward_norm='rms',\n",
    "        qk_norm='rms',          # Query/Keyの正規化（学習安定化のため）\n",
    "        use_bias=False,         # 最近のLLM/Transformerはバイアスを省く傾向\n",
    "        use_rotary_position_embeddings=True,\n",
    "        ff_activation='swish',\n",
    "        fuse_qkv=False\n",
    "    )\n",
    "    print(f\"\\n[TransformerConfig (Single Layer)]\\n Model Dims: {tf_layer_config.model_dims}, Heads: {tf_layer_config.num_heads}\")\n",
    "    print(f\" Norm Type: {tf_layer_config.attention_norm}, RoPE: {tf_layer_config.use_rotary_position_embeddings}\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 5. StackedTransformersConfig: 積み上げ設定\n",
    "    # ---------------------------------------------------------\n",
    "    # 上記の層を何層積み重ねるか定義\n",
    "    stacked_config = StackedTransformersConfig(\n",
    "        num_layers=20,          # 20層積み上げ\n",
    "        transformer=tf_layer_config\n",
    "    )\n",
    "    print(f\"\\n[StackedTransformersConfig]\\n Total Layers: {stacked_config.num_layers}\")\n",
    "    print(\" --> Configuration objects are ready for model initialization.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_config_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "971f290f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TimesFM Configuration Exploratory Verification ===\n",
      "\n",
      "Config Name          | Context  | Horizon  | Norm   | Bias   | Est. Params\n",
      "--------------------------------------------------------------------------------\n",
      "Small (Debug)        | 512      | 128      | rms    | True   | 9.44M     \n",
      "Small (Debug)        | 512      | 128      | rms    | False  | 9.44M     \n",
      "Small (Debug)        | 512      | 128      | layer  | True   | 9.44M     \n",
      "Small (Debug)        | 512      | 128      | layer  | False  | 9.44M     \n",
      "Base (200M)          | 512      | 128      | rms    | True   | 196.61M   \n",
      "Base (200M)          | 512      | 128      | rms    | False  | 196.61M   \n",
      "Base (200M)          | 512      | 128      | layer  | True   | 196.61M   \n",
      "Base (200M)          | 512      | 128      | layer  | False  | 196.61M   \n",
      "Large (Production)   | 512      | 128      | rms    | True   | 1.26B     \n",
      "Large (Production)   | 512      | 128      | rms    | False  | 1.26B     \n",
      "Large (Production)   | 512      | 128      | layer  | True   | 1.26B     \n",
      "Large (Production)   | 512      | 128      | layer  | False  | 1.26B     \n",
      "Small (Debug)        | 2048     | 512      | rms    | True   | 9.44M     \n",
      "Small (Debug)        | 2048     | 512      | rms    | False  | 9.44M     \n",
      "Small (Debug)        | 2048     | 512      | layer  | True   | 9.44M     \n",
      "Small (Debug)        | 2048     | 512      | layer  | False  | 9.44M     \n",
      "Base (200M)          | 2048     | 512      | rms    | True   | 196.61M   \n",
      "Base (200M)          | 2048     | 512      | rms    | False  | 196.61M   \n",
      "Base (200M)          | 2048     | 512      | layer  | True   | 196.61M   \n",
      "Base (200M)          | 2048     | 512      | layer  | False  | 196.61M   \n",
      "Large (Production)   | 2048     | 512      | rms    | True   | 1.26B     \n",
      "Large (Production)   | 2048     | 512      | rms    | False  | 1.26B     \n",
      "Large (Production)   | 2048     | 512      | layer  | True   | 1.26B     \n",
      "Large (Production)   | 2048     | 512      | layer  | False  | 1.26B     \n",
      "\n",
      "=== Verification Complete ===\n",
      "ヒント: 'Small'構成は手元のCPUでのデバッグや単体テストに最適です。\n",
      "ヒント: 'Base'構成が配布されているTimesFM-2.5のチェックポイントと互換性があります。\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from timesfm.configs import (\n",
    "    ForecastConfig,\n",
    "    TransformerConfig,\n",
    "    StackedTransformersConfig,\n",
    "    ResidualBlockConfig,\n",
    "    RandomFourierFeaturesConfig\n",
    ")\n",
    "\n",
    "def format_size(num):\n",
    "    \"\"\"パラメータ数を読みやすくフォーマット\"\"\"\n",
    "    if num >= 1_000_000_000:\n",
    "        return f\"{num / 1_000_000_000:.2f}B\"\n",
    "    elif num >= 1_000_000:\n",
    "        return f\"{num / 1_000_000:.2f}M\"\n",
    "    else:\n",
    "        return f\"{num / 1_000:.2f}K\"\n",
    "\n",
    "def estimate_params(t_config, s_config):\n",
    "    \"\"\"\n",
    "    Transformerのおおよそのパラメータ数を概算する関数\n",
    "    (注意: 正確な実装依存のバイアス等は無視した簡易計算)\n",
    "    \"\"\"\n",
    "    d_model = t_config.model_dims\n",
    "    d_ff = t_config.hidden_dims\n",
    "    n_layers = s_config.num_layers\n",
    "    \n",
    "    # 1層あたりの概算\n",
    "    # Attention: 4 * d_model^2 (Q,K,V,Output)\n",
    "    # FFN: 2 * d_model * d_ff (Up, Down)\n",
    "    attn_params = 4 * (d_model ** 2)\n",
    "    ffn_params = 2 * (d_model * d_ff)\n",
    "    \n",
    "    layer_params = attn_params + ffn_params\n",
    "    total_params = layer_params * n_layers\n",
    "    \n",
    "    return total_params\n",
    "\n",
    "def exploratory_config_generation():\n",
    "    print(\"=== TimesFM Configuration Exploratory Verification ===\\n\")\n",
    "\n",
    "    # 1. 検証したいハイパーパラメータの候補を定義（探索空間）\n",
    "    search_space = {\n",
    "        'context_horizon': [(512, 128), (2048, 512)], # (Context, Horizon)\n",
    "        'model_size': [\n",
    "            {'d_model': 512, 'heads': 8, 'layers': 6, 'name': 'Small (Debug)'},\n",
    "            {'d_model': 1280, 'heads': 16, 'layers': 20, 'name': 'Base (200M)'},\n",
    "            {'d_model': 2560, 'heads': 20, 'layers': 32, 'name': 'Large (Production)'},\n",
    "        ],\n",
    "        'norms': ['rms', 'layer'],\n",
    "        'use_bias': [True, False]\n",
    "    }\n",
    "\n",
    "    # 2. 組み合わせを生成して検証\n",
    "    print(f\"{'Config Name':<20} | {'Context':<8} | {'Horizon':<8} | {'Norm':<6} | {'Bias':<6} | {'Est. Params':<10}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # itertools.productで全組み合わせを探索\n",
    "    for (ctx, hor), size_conf, norm, bias in itertools.product(\n",
    "        search_space['context_horizon'],\n",
    "        search_space['model_size'],\n",
    "        search_space['norms'],\n",
    "        search_space['use_bias']\n",
    "    ):\n",
    "        # 設定オブジェクトの生成検証\n",
    "        try:\n",
    "            # Forecast Config\n",
    "            f_conf = ForecastConfig(\n",
    "                max_context=ctx,\n",
    "                max_horizon=hor,\n",
    "                normalize_inputs=True,\n",
    "                window_size=ctx + hor + 128,\n",
    "                per_core_batch_size=32\n",
    "            )\n",
    "            \n",
    "            # Transformer Config\n",
    "            t_conf = TransformerConfig(\n",
    "                model_dims=size_conf['d_model'],\n",
    "                hidden_dims=size_conf['d_model'], # TimesFM style\n",
    "                num_heads=size_conf['heads'],\n",
    "                attention_norm=norm,\n",
    "                feedforward_norm=norm,\n",
    "                qk_norm=norm,\n",
    "                use_bias=bias,\n",
    "                use_rotary_position_embeddings=True,\n",
    "                ff_activation='swish',\n",
    "                fuse_qkv=True\n",
    "            )\n",
    "            \n",
    "            # Stacked Config\n",
    "            s_conf = StackedTransformersConfig(\n",
    "                num_layers=size_conf['layers'],\n",
    "                transformer=t_conf\n",
    "            )\n",
    "            \n",
    "            # パラメータ数概算\n",
    "            param_count = estimate_params(t_conf, s_conf)\n",
    "            \n",
    "            # 結果表示\n",
    "            print(f\"{size_conf['name']:<20} | {ctx:<8} | {hor:<8} | {norm:<6} | {str(bias):<6} | {format_size(param_count):<10}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Invalid Config Combination: {e}\")\n",
    "\n",
    "    print(\"\\n=== Verification Complete ===\")\n",
    "    print(\"ヒント: 'Small'構成は手元のCPUでのデバッグや単体テストに最適です。\")\n",
    "    print(\"ヒント: 'Base'構成が配布されているTimesFM-2.5のチェックポイントと互換性があります。\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    exploratory_config_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac436d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TimesFM Attention Mask Demo (Fixed) ===\n",
      "\n",
      "Success! Mask shape: (2, 1, 4, 4)\n",
      "\n",
      "--- Mask Content (Batch 0) ---\n",
      "[[ True False False False]\n",
      " [ True  True False False]\n",
      " [ True  True  True False]\n",
      " [ True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from timesfm.flax.transformer import make_attn_mask\n",
    "\n",
    "def demo_make_attn_mask_fixed():\n",
    "    print(\"=== TimesFM Attention Mask Demo (Fixed) ===\\n\")\n",
    "\n",
    "    # 設定: バッチサイズ=2, シーケンス長=4\n",
    "    batch_size = 2\n",
    "    seq_len = 4\n",
    "    \n",
    "    # 修正1: num_all_masked_kv は (Batch,) の形状を持つ配列にする\n",
    "    # ここでは「パディングなし（全てのトークンが有効）」として 0 を指定\n",
    "    num_all_masked_kv = jnp.zeros((batch_size,), dtype=jnp.int32)\n",
    "    \n",
    "    # 修正2: query_index_offset も同様に配列で指定（オフセットなしなら 0）\n",
    "    query_index_offset = jnp.zeros((batch_size,), dtype=jnp.int32)\n",
    "\n",
    "    try:\n",
    "        mask = make_attn_mask(\n",
    "            query_length=seq_len, \n",
    "            num_all_masked_kv=num_all_masked_kv,  # 必須: JAX配列\n",
    "            query_index_offset=query_index_offset, # 推奨: JAX配列\n",
    "            kv_length=seq_len\n",
    "        )\n",
    "        \n",
    "        print(f\"Success! Mask shape: {mask.shape}\")\n",
    "        # 期待される形状: (Batch, 1, Query, Key) -> (2, 1, 4, 4)\n",
    "        \n",
    "        print(\"\\n--- Mask Content (Batch 0) ---\")\n",
    "        # 1 = Attention可能, 0 = Mask\n",
    "        # 下三角行列（未来の情報をマスク）になっているか確認\n",
    "        print(mask[0, 0, :, :])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo_make_attn_mask_fixed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaa89ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import nnx\n",
    "\n",
    "# --- 修正版インポート ---\n",
    "from timesfm.flax.util import revin  # revinはutilのまま\n",
    "from timesfm.flax.transformer import make_attn_mask, Transformer, RotaryPositionalEmbedding # make_attn_maskはこちら\n",
    "from timesfm.configs import TransformerConfig\n",
    "\n",
    "def demo_flax_components_fixed():\n",
    "    print(\"=== TimesFM Flax Components Demo (Fixed) ===\\n\")\n",
    "\n",
    "    # 1. RevIN Demo\n",
    "    # (コードは前回と同じですが、インポートが正しければ動作します)\n",
    "    x = jnp.array([[[100.0], [102.0], [105.0]], [[1.0], [2.0], [1.0]]])\n",
    "    mu = jnp.mean(x, axis=1, keepdims=True)\n",
    "    sigma = jnp.std(x, axis=1, keepdims=True) + 1e-6\n",
    "    \n",
    "    # revinのテスト\n",
    "    x_norm = revin(x=x, mu=mu, sigma=sigma, reverse=False)\n",
    "    print(f\"RevIN Normalized shape: {x_norm.shape}\")\n",
    "\n",
    "    # 2. Attention Mask Demo\n",
    "    # 正しいモジュールからインポートされた make_attn_mask を使用\n",
    "    try:\n",
    "        mask = make_attn_mask(\n",
    "            query_length=4, \n",
    "            num_all_masked_kv=None, # 必須引数として定義されている場合があるためNoneまたは適切な値を指定\n",
    "            query_index_offset=None,\n",
    "            kv_length=4\n",
    "        )\n",
    "        print(f\"Attention Mask created: {mask.shape}\")\n",
    "        # (Batch, 1, Query, Key) のような形状になるはずです\n",
    "        print(mask[0, 0, :, :]) \n",
    "        \n",
    "    except TypeError as e:\n",
    "        # 引数が足りない場合のフォールバック（バージョンによって引数が異なる可能性があります）\n",
    "        print(f\"Mask creation check: {e}\")\n",
    "        # 簡易版呼び出し（スタブの定義に基づく）\n",
    "        mask = make_attn_mask(query_length=4, kv_length=4)\n",
    "        print(\"Mask created with minimal args.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo_flax_components_fixed()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
