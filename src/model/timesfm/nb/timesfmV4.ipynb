{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fea0f8b",
   "metadata": {},
   "source": [
    "# `make_attn_mask`（TimesFM / Flax）\n",
    "\n",
    "`make_attn_mask`は、Transformerの注意(Attention)で使う **マスク(mask)** を作ります。\n",
    "\n",
    "- **因果マスク(causal mask)**：未来トークン(右側)を見ないようにする  \n",
    "  → `q_index >= kv_index`\n",
    "- **左パディング(left padding)の無視**：系列の先頭にある無効パッチ(例：パディング)を見ない  \n",
    "  → `kv_index >= num_all_masked_kv`\n",
    "\n",
    "返り値は `bool` の配列で、形状は **`[b, 1, q, n]`** です。\n",
    "- `b`：バッチサイズ\n",
    "- `q`：`query_length`\n",
    "- `n`：`kv_length`（ただし `kv_length=0` のときは `query_length` と同じ）\n",
    "\n",
    "> 注意：`query_length` と `kv_length` は `jax.jit` の `static_argnames` なので **Python の `int` を渡す必要**があります（`None`やJAX配列は不可）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e8a0f4",
   "metadata": {},
   "source": [
    "## 1) 学習/通常推論（キャッシュなし・自己注意：kv_length=0 → kv_length=query_length扱い）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5a3528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2026-02-11 23:25:54,914:jax._src.xla_bridge:876: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "WARNING:jax._src.xla_bridge:An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 8, 8)\n",
      "bool\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "from timesfm.flax.transformer import make_attn_mask\n",
    "\n",
    "# 例：バッチサイズ b=2\n",
    "query_length = 8  # int（必須）\n",
    "num_all_masked_kv = jnp.array([0, 2], dtype=jnp.int32)  # 先頭から無視するKV数（左パディング数）\n",
    "\n",
    "attn_mask = make_attn_mask(\n",
    "    query_length=query_length,\n",
    "    num_all_masked_kv=num_all_masked_kv,\n",
    "    query_index_offset=None,\n",
    "    kv_length=0,  # 0ならkv_length=query_lengthになる\n",
    ")\n",
    "\n",
    "print(attn_mask.shape)  # (2, 1, 8, 8)\n",
    "print(attn_mask.dtype)  # bool\n",
    "attn_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35bed4c",
   "metadata": {},
   "source": [
    "## 2) デコード/キャッシュあり（query_index_offsetとkv_lengthを使う）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "897b1dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 4, 16)\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "from timesfm.flax.transformer import make_attn_mask\n",
    "\n",
    "b = 2\n",
    "query_length = 4      # 今回追加するクエリ長（例：新しいパッチ数）\n",
    "kv_length = 16        # キャッシュに既にあるKV長（例：decode_cache_size）\n",
    "num_all_masked_kv = jnp.array([0, 1], dtype=jnp.int32)  # 左パディング数\n",
    "query_index_offset = jnp.array([8, 12], dtype=jnp.int32)  # 各バッチの“今回の書き込み開始位置”(next_index相当)\n",
    "\n",
    "attn_mask = make_attn_mask(\n",
    "    query_length=query_length,\n",
    "    num_all_masked_kv=num_all_masked_kv,\n",
    "    query_index_offset=query_index_offset,\n",
    "    kv_length=kv_length,\n",
    ")\n",
    "\n",
    "print(attn_mask.shape)  # (2, 1, 4, 16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8664d10e",
   "metadata": {},
   "source": [
    "## ForecastConfig (予測設定)\n",
    "予測時のパラメータ（ホライズン、コンテキスト長、正規化など）を管理するクラスです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "600bae86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ForecastConfig: context=512, horizon=128\n"
     ]
    }
   ],
   "source": [
    "from timesfm.configs import ForecastConfig\n",
    "\n",
    "# 予測設定の作成\n",
    "# モデルのデフォルトに合わせて設定します（例: context=512, horizon=128）\n",
    "forecast_config = ForecastConfig(\n",
    "    max_context=512,          # モデルに入力する最大過去データ点数\n",
    "    max_horizon=128,          # 一度に予測する最大ステップ数\n",
    "    normalize_inputs=True,    # 入力データを正規化するか (RevIN等)\n",
    "    window_size=0,            # 分解予測時のウィンドウサイズ (0は無効)\n",
    "    per_core_batch_size=32,   # コアごとのバッチサイズ\n",
    "    use_continuous_quantile_head=False, # 連続分位点ヘッドの使用有無\n",
    "    force_flip_invariance=True, # 反転不変性を強制するか (時系列の上下反転に対して頑健にする)\n",
    "    infer_is_positive=False,    # 出力が非負であることを強制するか\n",
    "    fix_quantile_crossing=True, # 分位点の交差（矛盾）を修正するか\n",
    "    return_backcast=False       # 過去データの再構成を返すか\n",
    ")\n",
    "\n",
    "print(f\"ForecastConfig: context={forecast_config.max_context}, horizon={forecast_config.max_horizon}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0f7840",
   "metadata": {},
   "source": [
    "## StackedTransformersConfig & TransformerConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d4f59b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Config: 20 layers, 1280 dims\n"
     ]
    }
   ],
   "source": [
    "from timesfm.configs import TransformerConfig, StackedTransformersConfig\n",
    "\n",
    "# 1. 個別のTransformer層の詳細設定\n",
    "transformer_config = TransformerConfig(\n",
    "    model_dims=1280,      # モデル次元 (d_model)\n",
    "    hidden_dims=1280,     # FFNの隠れ次元\n",
    "    num_heads=16,         # 注意ヘッド数\n",
    "    attention_norm='rms', # Attention正規化方式 (RMSNorm)\n",
    "    feedforward_norm='rms', # FFN正規化方式\n",
    "    qk_norm='rms',        # Query/Key正規化方式\n",
    "    use_bias=False,       # 線形層にバイアスを使うか\n",
    "    use_rotary_position_embeddings=True, # RoPE (回転位置埋め込み)\n",
    "    ff_activation='swish',# FFN活性化関数\n",
    "    fuse_qkv=True         # QKVを融合実装するか (高速化)\n",
    ")\n",
    "\n",
    "# 2. Transformerを積み上げる設定\n",
    "stacked_config = StackedTransformersConfig(\n",
    "    num_layers=20,                 # 積み上げる層数\n",
    "    transformer=transformer_config # 上記の設定を適用\n",
    ")\n",
    "\n",
    "print(f\"Model Config: {stacked_config.num_layers} layers, {transformer_config.model_dims} dims\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220db8e1",
   "metadata": {},
   "source": [
    "## 2. Flax ユーティリティ (Flax Utilities)\n",
    "時系列特有の前処理やAttentionマスク生成などの低レイヤー関数です。\n",
    "\n",
    "revin (Reverse Instance Normalization)\n",
    "時系列データの分布シフトに対処するため、入力データを平均・分散で正規化し、出力後に逆変換するための関数です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05bb82c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized (mean approx 0):\n",
      " [-1.4142126 -0.7071063  0.         0.7071063  1.4142126]\n",
      "Reconstructed:\n",
      " [10. 11. 12. 13. 14.]\n",
      "RevIN check passed.\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from timesfm.flax.util import revin\n",
    "\n",
    "# ダミーデータ: [batch=2, seq_len=10, dim=1]\n",
    "x_dummy = jnp.array([\n",
    "    [10.0, 11.0, 12.0, 13.0, 14.0],\n",
    "    [100.0, 101.0, 102.0, 103.0, 104.0]\n",
    "]).reshape(2, 5, 1)\n",
    "\n",
    "# 統計量 (ここでは単純化のため手動設定、通常は計算して求める)\n",
    "mu = jnp.mean(x_dummy, axis=1, keepdims=True)\n",
    "sigma = jnp.std(x_dummy, axis=1, keepdims=True) + 1e-6\n",
    "\n",
    "# 1. 正規化 (Forward)\n",
    "x_norm = revin(x=x_dummy, mu=mu, sigma=sigma, reverse=False)\n",
    "print(\"Normalized (mean approx 0):\\n\", x_norm[0].flatten())\n",
    "\n",
    "# 2. 逆変換 (Reverse)\n",
    "x_recon = revin(x=x_norm, mu=mu, sigma=sigma, reverse=True)\n",
    "print(\"Reconstructed:\\n\", x_recon[0].flatten())\n",
    "\n",
    "# 元に戻っているか確認\n",
    "assert jnp.allclose(x_dummy, x_recon, atol=1e-5)\n",
    "print(\"RevIN check passed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a3d6c0",
   "metadata": {},
   "source": [
    "## make_attn_mask (Attention Mask)\n",
    "TransformerのSelf-Attentionで使用する因果マスクを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4eedfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask shape: (2, 1, 8, 8)\n",
      "Mask sample 0 (True=Attend, False=Masked):\n",
      " [[1 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 0]\n",
      " [1 1 1 0 0 0 0 0]\n",
      " [1 1 1 1 0 0 0 0]\n",
      " [1 1 1 1 1 0 0 0]\n",
      " [1 1 1 1 1 1 0 0]\n",
      " [1 1 1 1 1 1 1 0]\n",
      " [1 1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from timesfm.flax.transformer import make_attn_mask\n",
    "\n",
    "# バッチサイズ2, クエリ長8\n",
    "query_len = 8\n",
    "num_masked_kv = jnp.array([0, 2], dtype=jnp.int32) # バッチ内の各サンプルで無視する先頭トークン数\n",
    "\n",
    "mask = make_attn_mask(\n",
    "    query_length=query_len,\n",
    "    num_all_masked_kv=num_masked_kv,\n",
    "    kv_length=0 # 0の場合 query_length と同じとみなされる\n",
    ")\n",
    "\n",
    "print(f\"Mask shape: {mask.shape}\") # (2, 1, 8, 8)\n",
    "# マスクの可視化 (1つ目のサンプル)\n",
    "print(\"Mask sample 0 (True=Attend, False=Masked):\\n\", mask[0, 0].astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfe6562",
   "metadata": {},
   "source": [
    "## 3. TimesFM 2.5 モデル利用 (Main Model Usage)\n",
    "高レベルAPIを使用したモデルのロードと推論のワークフローです。\n",
    "\n",
    "TimesFM_2p5 クラスの初期化とチェックポイントロード\n",
    "これは flax と torch のバックエンドをラップする高レベルクラスである可能性がありますが、ここでは from_pretrained メソッドを持つ TimesFM_2p5_200M_flax を例にします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e6fc330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e455fb5c9245a0a9b6c6f4ece05727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb14aa614bb84ca7a5a414c2eb30f7f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "99d9838f4ea666b0baf271caec0acb55:   0%|          | 0.00/1.64k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8da3ac562e74dc6b5f2edf3eca1c870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_CHECKPOINT_METADATA:   0%|          | 0.00/262 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0990631216347afa059b7a45127c65f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_sharding: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965741a589a1422985b5828613f6f667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "process_0: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cffbf18418ae4578b8005f81750bd429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/31.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8806c01f2b848cca9e379d6c357f289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_METADATA: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b41522fd7494a00a1e33a303f19c68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "descriptor.pbtxt:   0%|          | 0.00/537 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a503d77d20a0476da1486f6ecec42f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa37cde54b046fe90611a12b0c35da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ocdbt.process_0/d/391be1dabf9d22a13dbd77(…):   0%|          | 0.00/129M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d5b57cb106477aa19732c63c87c046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "82e3580474fe958b6aca1f086b1801bb:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e9fb12537404d8ab8ad8c2fcfbcfadd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ocdbt.process_0/d/f933434baa602db9432904(…):   0%|          | 0.00/729M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d060094a7164c9383fff891badf7895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "manifest.ocdbt:   0%|          | 0.00/117 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b3eee8818940099f30fca971aef45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)uid-1268afaf-1c19-4568-8171-17e9c4ca2504:   0%|          | 0.00/45.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645608fad29c4916b2924f309e95f533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "manifest.ocdbt:   0%|          | 0.00/266 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347b8e6b096144a9a527314c2ab078b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "f0a794078cf86d67e5026770a0cb3aaa:   0%|          | 0.00/590 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimesFM model instance created.\n"
     ]
    }
   ],
   "source": [
    "from timesfm.timesfm_2p5.timesfm_2p5_flax import TimesFM_2p5_200M_flax\n",
    "\n",
    "# モデルのインスタンス化\n",
    "# 注意: 実際にHugging Faceからダウンロードする場合は時間がかかります\n",
    "tfm_model = TimesFM_2p5_200M_flax()\n",
    "\n",
    "# 事前学習済みモデルのロード (例)\n",
    "tfm_model.from_pretrained(\n",
    "    model_id='google/timesfm-2.5-200m-flax',\n",
    "    force_download=False\n",
    ")\n",
    "print(\"TimesFM model instance created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03d5fb8",
   "metadata": {},
   "source": [
    "## forecast (予測実行)\n",
    "入力データを与えて未来を予測します。ここではモックデータでの呼び出しイメージを示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ca5ccf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/az/miniconda3/envs/ts/lib/python3.11/site-packages/jax/_src/interpreters/mlir.py:1274: UserWarning: Some donated buffers were not usable: float32[1,32,16,128,10], float32[1,32,16,128,10], float32[32,1], float32[32,1].\n",
      "See an explanation at https://docs.jax.dev/en/latest/faq.html#buffer-donation.\n",
      "  warnings.warn(\"Some donated buffers were not usable:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling done.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ダミーの時系列データ (リスト形式)\n",
    "# 2つの時系列: 長さ 64\n",
    "inputs = [\n",
    "    np.sin(np.linspace(0, 20, 64)),\n",
    "    np.cos(np.linspace(0, 20, 64)) * 10\n",
    "]\n",
    "\n",
    "# コンパイル (JITコンパイルが走るため初回は遅い)\n",
    "# 注意: 実際の重みがロードされていないとランダムな出力になります\n",
    "tfm_model.compile(forecast_config=forecast_config)\n",
    "\n",
    "# 予測実行 (コメントアウトを外して実行)\n",
    "forecast_result = tfm_model.forecast(\n",
    "    horizon=32,\n",
    "    inputs=inputs\n",
    ")\n",
    "\n",
    "# print(\"Forecast shape:\", forecast_result.shape) # (2, 32, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50692101",
   "metadata": {},
   "source": [
    "## 4. Torch コンポーネント (Torch Components)\n",
    "PyTorch環境でのコンポーネント確認です。\n",
    "\n",
    "MultiHeadAttention (Torch)\n",
    "PyTorch版のMulti-Head Attentionモジュールの動作確認です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99ed8e81",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Forward\u001b[39;00m\n\u001b[32m     22\u001b[39m output = mha.forward(\n\u001b[32m     23\u001b[39m     inputs_q=x_torch,\n\u001b[32m     24\u001b[39m     decode_cache=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     25\u001b[39m     patch_mask=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     26\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTorch MHA Output shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# (2, 16, 64)\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from timesfm.torch.transformer import MultiHeadAttention\n",
    "\n",
    "# 設定\n",
    "dim = 64\n",
    "heads = 4\n",
    "\n",
    "# モジュール初期化\n",
    "mha = MultiHeadAttention(\n",
    "    num_heads=heads,\n",
    "    in_features=dim,\n",
    "    use_per_dim_scale=True,\n",
    "    use_rotary_position_embeddings=True,\n",
    "    use_bias=False,\n",
    "    qk_norm='rms'\n",
    ")\n",
    "\n",
    "# ダミー入力 [Batch, Length, Dim]\n",
    "x_torch = torch.randn(2, 16, dim)\n",
    "\n",
    "# Forward\n",
    "output = mha.forward(\n",
    "    inputs_q=x_torch,\n",
    "    decode_cache=None,\n",
    "    patch_mask=None\n",
    ")\n",
    "\n",
    "print(f\"Torch MHA Output shape: {output.shape}\") # (2, 16, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd061eda",
   "metadata": {},
   "source": [
    "## 5. 共変量 (XReg / Covariates)\n",
    "TimesFMは外部共変量（休日、天気、カテゴリ情報など）を扱うために、In-Contextでの線形回帰などを組み合わせる XReg モジュールを持っています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4691f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timesfm.utils.xreg_lib import BatchedInContextXRegLinear\n",
    "\n",
    "# データ準備\n",
    "# ターゲット: [2つの系列, 長さ100]\n",
    "targets = [\n",
    "    [x * 0.1 + 2.0 for x in range(100)],\n",
    "    [x * -0.05 + 10.0 for x in range(100)]\n",
    "]\n",
    "train_lens = [80, 80] # 学習期間\n",
    "test_lens = [20, 20]  # テスト（予測）期間\n",
    "\n",
    "# 静的共変量（各系列に紐づく固定値、例: 店舗IDの埋め込みなど）\n",
    "# ここではダミー\n",
    "static_numerical = [[1.0], [0.5]]\n",
    "\n",
    "# XRegモデルの初期化\n",
    "xreg = BatchedInContextXRegLinear(\n",
    "    targets=targets,\n",
    "    train_lens=train_lens,\n",
    "    test_lens=test_lens,\n",
    "    static_numerical_covariates=static_numerical,\n",
    "    # 動的共変量がある場合は以下に追加\n",
    "    # train_dynamic_numerical_covariates=...,\n",
    ")\n",
    "\n",
    "# フィッティング (Ridge回帰など)\n",
    "xreg.fit(ridge=1.0)\n",
    "\n",
    "print(\"XReg fitting completed.\")\n",
    "# 内部では共変量行列を作成し、最小二乗法などで係数を推定しています"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee3f1db",
   "metadata": {},
   "source": [
    "## normalize (正規化ユーティリティ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timesfm.utils.xreg_lib import normalize\n",
    "\n",
    "batch_data = np.array([\n",
    "    [10, 20, 30],\n",
    "    [100, 200, 300]\n",
    "], dtype=float)\n",
    "\n",
    "# バッチごとの正規化\n",
    "normalized_batch, stats = normalize(batch_data)\n",
    "\n",
    "print(\"Mean:\", stats.mean)\n",
    "print(\"Std:\", stats.std)\n",
    "print(\"Normalized:\\n\", normalized_batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
