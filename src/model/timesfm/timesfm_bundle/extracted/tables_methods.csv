ID,Parent,Type,Name,Path,Module,Docstring,Params,ReturnType
3,2,method,__init__,timesfm.data_loader.TimeSeriesdata.__init__,timesfm.data_loader,Initialize objects.\n\nArgs:\n data_path: path to csv file\n datetime_col: column name for datetime col\n num_cov_cols: list of numerical global covariates\n cat_cov_cols: list of categorical global covariates\n ts_cols: columns corresponding to ts\n train_range: tuple of train ranges\n val_range: tuple of validation ranges\n test_range: tuple of test ranges\n hist_len: historical context\n pred_len: prediction length\n batch_size: batch size (number of ts in a batch)\n freq: freq of original data\n normalize: std. normalize data or not\n epoch_len: num iters in an epoch\n holiday: use holiday features or not\n permute: permute ts in train batches or not\n\nReturns:\n None,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'data_path', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'datetime_col', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'num_cov_cols', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'cat_cov_cols', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'ts_cols', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'train_range', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'val_range', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'test_range', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'hist_len', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'pred_len', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'batch_size', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'freq', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': True, 'default_repr': ''H''}, {'name': 'normalize', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': True, 'default_repr': 'True'}, {'name': 'epoch_len', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': True, 'default_repr': 'None'}, {'name': 'holiday', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': True, 'default_repr': 'False'}, {'name': 'permute', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': True, 'default_repr': 'True'}]",
4,2,method,_get_cat_cols,timesfm.data_loader.TimeSeriesdata._get_cat_cols,timesfm.data_loader,Get categorical columns.,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'cat_cov_cols', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",
5,2,method,_normalize_data,timesfm.data_loader.TimeSeriesdata._normalize_data,timesfm.data_loader,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",
6,2,method,train_gen,timesfm.data_loader.TimeSeriesdata.train_gen,timesfm.data_loader,Generator for training data.,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",
7,2,method,test_val_gen,timesfm.data_loader.TimeSeriesdata.test_val_gen,timesfm.data_loader,Generator for validation/test data.,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'mode', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': True, 'default_repr': ''val''}, {'name': 'shift', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': True, 'default_repr': '1'}]",
8,2,method,_get_features_and_ts,timesfm.data_loader.TimeSeriesdata._get_features_and_ts,timesfm.data_loader,Get features and ts in specified windows.,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'dtimes', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'tsidx', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'hist_len', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': True, 'default_repr': 'None'}]",
9,2,method,tf_dataset,timesfm.data_loader.TimeSeriesdata.tf_dataset,timesfm.data_loader,Tensorflow Dataset.,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'mode', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': True, 'default_repr': ''train''}, {'name': 'shift', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': True, 'default_repr': '1'}]",
18,17,method,__init__,timesfm.time_features.TimeCovariates.__init__,timesfm.time_features,Init function.\n\nArgs:\n datetimes: pandas DatetimeIndex (lowest granularity supported is min)\n normalized: whether to normalize features or not\n holiday: fetch holiday features or not\n\nReturns:\n None,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'datetimes', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'normalized', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': True, 'default_repr': 'True'}, {'name': 'holiday', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': True, 'default_repr': 'False'}]",
19,17,method,_minute_of_hour,timesfm.time_features.TimeCovariates._minute_of_hour,timesfm.time_features,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",
20,17,method,_hour_of_day,timesfm.time_features.TimeCovariates._hour_of_day,timesfm.time_features,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",
21,17,method,_day_of_week,timesfm.time_features.TimeCovariates._day_of_week,timesfm.time_features,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",
22,17,method,_day_of_month,timesfm.time_features.TimeCovariates._day_of_month,timesfm.time_features,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",
23,17,method,_day_of_year,timesfm.time_features.TimeCovariates._day_of_year,timesfm.time_features,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",
24,17,method,_month_of_year,timesfm.time_features.TimeCovariates._month_of_year,timesfm.time_features,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",
25,17,method,_week_of_year,timesfm.time_features.TimeCovariates._week_of_year,timesfm.time_features,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",
26,17,method,_get_holidays,timesfm.time_features.TimeCovariates._get_holidays,timesfm.time_features,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",
27,17,method,get_covariates,timesfm.time_features.TimeCovariates.get_covariates,timesfm.time_features,Get all time covariates.,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",
47,46,method,__init__,timesfm.pytorch_patched_decoder.ResidualBlock.__init__,timesfm.pytorch_patched_decoder,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'input_dims', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'hidden_dims', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'output_dims', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",
48,46,method,forward,timesfm.pytorch_patched_decoder.ResidualBlock.forward,timesfm.pytorch_patched_decoder,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'x', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",
50,49,method,__init__,timesfm.pytorch_patched_decoder.RMSNorm.__init__,timesfm.pytorch_patched_decoder,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'dim', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': False, 'default_repr': ''}, {'name': 'eps', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'float', 'has_default': True, 'default_repr': '1e-06'}, {'name': 'add_unit_offset', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'bool', 'has_default': True, 'default_repr': 'False'}]",
51,49,method,_norm,timesfm.pytorch_patched_decoder.RMSNorm._norm,timesfm.pytorch_patched_decoder,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'x', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",
52,49,method,forward,timesfm.pytorch_patched_decoder.RMSNorm.forward,timesfm.pytorch_patched_decoder,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'x', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",
54,53,method,__init__,timesfm.pytorch_patched_decoder.TransformerMLP.__init__,timesfm.pytorch_patched_decoder,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'hidden_size', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': False, 'default_repr': ''}, {'name': 'intermediate_size', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': False, 'default_repr': ''}]",
55,53,method,forward,timesfm.pytorch_patched_decoder.TransformerMLP.forward,timesfm.pytorch_patched_decoder,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'x', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'paddings', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': True, 'default_repr': 'None'}]",
57,56,method,__init__,timesfm.pytorch_patched_decoder.TimesFMAttention.__init__,timesfm.pytorch_patched_decoder,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'hidden_size', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': False, 'default_repr': ''}, {'name': 'num_heads', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': False, 'default_repr': ''}, {'name': 'num_kv_heads', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': False, 'default_repr': ''}, {'name': 'head_dim', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': False, 'default_repr': ''}]",
58,56,method,_per_dim_scaling,timesfm.pytorch_patched_decoder.TimesFMAttention._per_dim_scaling,timesfm.pytorch_patched_decoder,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'query', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'torch.Tensor', 'has_default': False, 'default_repr': ''}]",torch.Tensor
59,56,method,forward,timesfm.pytorch_patched_decoder.TimesFMAttention.forward,timesfm.pytorch_patched_decoder,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'hidden_states', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'torch.Tensor', 'has_default': False, 'default_repr': ''}, {'name': 'mask', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'torch.Tensor', 'has_default': False, 'default_repr': ''}, {'name': 'kv_write_indices', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'torch.Tensor | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'kv_cache', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Tuple[torch.Tensor, torch.Tensor] | None', 'has_default': True, 'default_repr': 'None'}]",torch.Tensor
61,60,method,__init__,timesfm.pytorch_patched_decoder.TimesFMDecoderLayer.__init__,timesfm.pytorch_patched_decoder,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'hidden_size', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': False, 'default_repr': ''}, {'name': 'intermediate_size', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': False, 'default_repr': ''}, {'name': 'num_heads', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': False, 'default_repr': ''}, {'name': 'num_kv_heads', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': False, 'default_repr': ''}, {'name': 'head_dim', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': False, 'default_repr': ''}, {'name': 'rms_norm_eps', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'float', 'has_default': True, 'default_repr': '1e-06'}]",
62,60,method,forward,timesfm.pytorch_patched_decoder.TimesFMDecoderLayer.forward,timesfm.pytorch_patched_decoder,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'hidden_states', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'torch.Tensor', 'has_default': False, 'default_repr': ''}, {'name': 'mask', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'torch.Tensor', 'has_default': False, 'default_repr': ''}, {'name': 'paddings', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'torch.Tensor', 'has_default': False, 'default_repr': ''}, {'name': 'kv_write_indices', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'torch.Tensor | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'kv_cache', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Tuple[torch.Tensor, torch.Tensor] | None', 'has_default': True, 'default_repr': 'None'}]",torch.Tensor
64,63,method,__init__,timesfm.pytorch_patched_decoder.StackedDecoder.__init__,timesfm.pytorch_patched_decoder,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'hidden_size', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': False, 'default_repr': ''}, {'name': 'intermediate_size', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': False, 'default_repr': ''}, {'name': 'num_heads', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': False, 'default_repr': ''}, {'name': 'num_kv_heads', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': False, 'default_repr': ''}, {'name': 'head_dim', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': False, 'default_repr': ''}, {'name': 'num_layers', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': False, 'default_repr': ''}, {'name': 'rms_norm_eps', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'float', 'has_default': True, 'default_repr': '1e-06'}]",
65,63,method,forward,timesfm.pytorch_patched_decoder.StackedDecoder.forward,timesfm.pytorch_patched_decoder,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'hidden_states', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'torch.Tensor', 'has_default': False, 'default_repr': ''}, {'name': 'paddings', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'torch.Tensor', 'has_default': False, 'default_repr': ''}, {'name': 'kv_write_indices', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'torch.Tensor | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'kv_caches', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'List[Tuple[torch.Tensor, torch.Tensor]] | None', 'has_default': True, 'default_repr': 'None'}]",torch.Tensor
67,66,method,__init__,timesfm.pytorch_patched_decoder.PositionalEmbedding.__init__,timesfm.pytorch_patched_decoder,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'embedding_dims', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': False, 'default_repr': ''}, {'name': 'min_timescale', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': True, 'default_repr': '1'}, {'name': 'max_timescale', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': True, 'default_repr': '10000'}]",
68,66,method,forward,timesfm.pytorch_patched_decoder.PositionalEmbedding.forward,timesfm.pytorch_patched_decoder,"Generates a Tensor of sinusoids with different frequencies.\n\nArgs:\n seq_length: an optional Python int defining the output sequence length.\n if the `position` argument is specified.\n position: [B, seq_length], optional position for each token in the\n sequence, only required when the sequence is packed.\n\nReturns:\n [B, seqlen, D] if `position` is specified, else [1, seqlen, D]","[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'seq_length', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': True, 'default_repr': 'None'}, {'name': 'position', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': True, 'default_repr': 'None'}]",
70,69,method,__init__,timesfm.pytorch_patched_decoder.PatchedTimeSeriesDecoder.__init__,timesfm.pytorch_patched_decoder,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'config', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'TimesFMConfig', 'has_default': False, 'default_repr': ''}]",
71,69,method,_forward_transform,timesfm.pytorch_patched_decoder.PatchedTimeSeriesDecoder._forward_transform,timesfm.pytorch_patched_decoder,"Input is of shape [B, N, P].","[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'inputs', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'torch.Tensor', 'has_default': False, 'default_repr': ''}, {'name': 'patched_pads', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'torch.Tensor', 'has_default': False, 'default_repr': ''}]","tuple[torch.Tensor, tuple[torch.Tensor, torch.Tensor]]"
72,69,method,_reverse_transform,timesfm.pytorch_patched_decoder.PatchedTimeSeriesDecoder._reverse_transform,timesfm.pytorch_patched_decoder,"Output is of shape [B, N, P, Q].","[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'outputs', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'torch.Tensor', 'has_default': False, 'default_repr': ''}, {'name': 'stats', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'tuple[torch.Tensor, torch.Tensor]', 'has_default': False, 'default_repr': ''}]",torch.Tensor
73,69,method,_preprocess_input,timesfm.pytorch_patched_decoder.PatchedTimeSeriesDecoder._preprocess_input,timesfm.pytorch_patched_decoder,Preprocess input for stacked transformer.,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'input_ts', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'torch.Tensor', 'has_default': False, 'default_repr': ''}, {'name': 'input_padding', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'torch.Tensor', 'has_default': False, 'default_repr': ''}]","tuple[torch.Tensor, torch.Tensor, tuple[torch.Tensor, torch.Tensor] | None, torch.Tensor]"
74,69,method,_postprocess_output,timesfm.pytorch_patched_decoder.PatchedTimeSeriesDecoder._postprocess_output,timesfm.pytorch_patched_decoder,Postprocess output of stacked transformer.,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'model_output', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'torch.Tensor', 'has_default': False, 'default_repr': ''}, {'name': 'num_outputs', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': False, 'default_repr': ''}, {'name': 'stats', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'tuple[torch.Tensor, torch.Tensor]', 'has_default': False, 'default_repr': ''}]",torch.Tensor
75,69,method,forward,timesfm.pytorch_patched_decoder.PatchedTimeSeriesDecoder.forward,timesfm.pytorch_patched_decoder,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'input_ts', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'torch.Tensor', 'has_default': False, 'default_repr': ''}, {'name': 'input_padding', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'torch.LongTensor', 'has_default': False, 'default_repr': ''}, {'name': 'freq', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'torch.Tensor', 'has_default': False, 'default_repr': ''}]",torch.Tensor
76,69,method,decode,timesfm.pytorch_patched_decoder.PatchedTimeSeriesDecoder.decode,timesfm.pytorch_patched_decoder,"Auto-regressive decoding without caching.\n\nArgs:\n input_ts: input time-series and paddings. Time-series shape B x C.\n paddings: padding shape B x (C + H) where H is the prediction length.\n freq: frequency shape B x 1\n horizon_len: prediction length.\n output_patch_len: output length to be fetched from one step of\n auto-regressive decoding.\n max_len: maximum training context length.\n return_forecast_on_context: whether to return the model forecast on the\n context except the first input patch.\n\nReturns:\n Tuple of two forecasting results:\n - Point (mean) output predictions as a tensor with shape B x H'.\n - Full predictions (mean and quantiles) as a tensor with shape\n B x H' x (1 + # quantiles).\n In particular, if return_forecast_on_context is True, H' is H plus\n the forecastable context length, i.e. context_len - (first) patch_len.","[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'input_ts', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'torch.Tensor', 'has_default': False, 'default_repr': ''}, {'name': 'paddings', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'torch.Tensor', 'has_default': False, 'default_repr': ''}, {'name': 'freq', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'torch.LongTensor', 'has_default': False, 'default_repr': ''}, {'name': 'horizon_len', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': False, 'default_repr': ''}, {'name': 'output_patch_len', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'max_len', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'return_forecast_on_context', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'bool', 'has_default': True, 'default_repr': 'False'}]","tuple[torch.Tensor, torch.Tensor]"
84,83,method,_get_sample_inputs,timesfm.timesfm_jax.TimesFmJax._get_sample_inputs,timesfm.timesfm_jax,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",
85,83,method,__post_init__,timesfm.timesfm_jax.TimesFmJax.__post_init__,timesfm.timesfm_jax,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",
86,83,method,load_from_checkpoint,timesfm.timesfm_jax.TimesFmJax.load_from_checkpoint,timesfm.timesfm_jax,Loads a checkpoint and compiles the decoder.,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'checkpoint', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'timesfm_base.TimesFmCheckpoint', 'has_default': False, 'default_repr': ''}]",
87,83,method,jit_decode,timesfm.timesfm_jax.TimesFmJax.jit_decode,timesfm.timesfm_jax,Jitting decoding function.,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",
88,83,method,_forecast,timesfm.timesfm_jax.TimesFmJax._forecast,timesfm.timesfm_jax,"Forecasts on a list of time series.\n\nArgs:\n inputs: list of time series forecast contexts. Each context time series\n should be in a format convertible to JTensor by `jnp.array`.\n freq: frequency of each context time series. 0 for high frequency\n (default), 1 for medium, and 2 for low. Notice this is different from\n the `freq` required by `forecast_on_df`.\n window_size: window size of trend + residual decomposition. If None then\n we do not do decomposition.\n forecast_context_len: optional max context length.\n return_forecast_on_context: True to return the forecast on the context\n when available, i.e. after the first input patch.\n\nReturns:\nA tuple for JTensors:\n- the mean forecast of size (# inputs, # forecast horizon),\n- the full forecast (mean + quantiles) of size\n (# inputs, # forecast horizon, 1 + # quantiles).\n\nRaises:\nValueError: If the checkpoint is not properly loaded.","[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'inputs', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Sequence[Any]', 'has_default': False, 'default_repr': ''}, {'name': 'freq', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Sequence[int] | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'window_size', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'forecast_context_len', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'return_forecast_on_context', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'bool', 'has_default': True, 'default_repr': 'False'}]","tuple[np.ndarray, np.ndarray]"
107,106,method,__init__,timesfm.xreg_lib.BatchedInContextXRegBase.__init__,timesfm.xreg_lib,"Initializes with the exogenous covariate inputs.\n\nHere we use model fitting language to refer to the context as 'train' and\nthe horizon as 'test'. We assume batched inputs. To properly format the\nrequest:\n\n - `train_lens` represents the contexts in the batch. Targets and all train\n dynamic covariates should have the same lengths as the corresponding\n elements\n in `train_lens`. Notice each `train_len` can be different from the exact\n length of the corresponding context depending on how much of the context is\n used for fitting the in-context model.\n - `test_lens` represents the horizon lengths in the batch. All tesdt\n dynamic\n covariates should have the same lengths as the corresponding elements in\n `test_lens`.\n - Static covariates should be one for each input.\n - For train and test dynamic covariates, they should have the same\n covariate\n names.\n\n Pass an empty dict {} for a covariate type if it is not present.\n\n Example:\n Here is a set of valid inputs whose schema can be used for reference.\n ```\n targets = [\n [0.0, 0.1, 0.2],\n [0.0, 0.1, 0.2, 0.3],\n ] # Two inputs in this batch.\n train_lens = [3, 4]\n test_lens = [2, 5] # Forecast horizons 2 and 5 respectively.\n train_dynamic_numerical_covariates = {\n ""cov_1_dn"": [[0.0, 0.5, 1.0], [0.0, 0.5, 1.0, 1.5]],\n ""cov_2_dn"": [[0.0, 1.5, 1.0], [0.0, 1.5, 1.0, 2.5]],\n } # Each train dynamic covariate has 3 and 4 elements respectively.\n test_dynamic_numerical_covariates = {\n ""cov_1_dn"": [[0.1, 0.6], [0.1, 0.6, 1.1, 1.6, 2.4]],\n ""cov_2_dn"": [[0.1, 1.1], [0.1, 1.6, 1.1, 2.6, 10.0]],\n } # Each test dynamic covariate has 2 and 5 elements respectively.\n train_dynamic_categorical_covariates = {\n ""cov_1_dc"": [[0, 1, 0], [0, 1, 2, 3]],\n ""cov_2_dc"": [[""good"", ""bad"", ""good""], [""good"", ""good"", ""bad"",\n ""bad""]],\n }\n test_dynamic_categorical_covariates = {\n ""cov_1_dc"": [[1, 0], [1, 0, 2, 3, 1]],\n ""cov_2_dc"": [[""bad"", ""good""], [""bad"", ""bad"", ""bad"", ""bad"", ""bad""]],\n }\n static_numerical_covariates = {\n ""cov_1_sn"": [0.0, 3.0],\n ""cov_2_sn"": [2.0, 1.0],\n ""cov_3_sn"": [1.0, 2.0],\n } # Each static covariate has 1 element for each input.\n static_categorical_covariates = {\n ""cov_1_sc"": [""apple"", ""orange""],\n ""cov_2_sc"": [2, 3],\n }\n ```\n\nArgs:\n targets: List of targets (responses) of the in-context regression.\n train_lens: List of lengths of each target vector from the context.\n test_lens: List of lengths of each forecast horizon.\n train_dynamic_numerical_covariates: Dict of covariate names mapping to the\n dynamic numerical covariates of each forecast task on the context. Their\n lengths should match the corresponding lengths in `train_lens`.\n train_dynamic_categorical_covariates: Dict of covariate names mapping to\n the dynamic categorical covariates of each forecast task on the context.\n Their lengths should match the corresponding lengths in `train_lens`.\n test_dynamic_numerical_covariates: Dict of covariate names mapping to the\n dynamic numerical covariates of each forecast task on the horizon. Their\n lengths should match the corresponding lengths in `test_lens`.\n test_dynamic_categorical_covariates: Dict of covariate names mapping to\n the dynamic categorical covariates of each forecast task on the horizon.\n Their lengths should match the corresponding lengths in `test_lens`.\n static_numerical_covariates: Dict of covariate names mapping to the static\n numerical covariates of each forecast task.\n static_categorical_covariates: Dict of covariate names mapping to the\n static categorical covariates of each forecast task.","[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'targets', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Sequence[Sequence[float]]', 'has_default': False, 'default_repr': ''}, {'name': 'train_lens', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Sequence[int]', 'has_default': False, 'default_repr': ''}, {'name': 'test_lens', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Sequence[int]', 'has_default': False, 'default_repr': ''}, {'name': 'train_dynamic_numerical_covariates', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Mapping[str, Sequence[Sequence[float]]] | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'train_dynamic_categorical_covariates', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Mapping[str, Sequence[Sequence[Category]]] | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'test_dynamic_numerical_covariates', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Mapping[str, Sequence[Sequence[float]]] | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'test_dynamic_categorical_covariates', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Mapping[str, Sequence[Sequence[Category]]] | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'static_numerical_covariates', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Mapping[str, Sequence[float]] | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'static_categorical_covariates', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Mapping[str, Sequence[Category]] | None', 'has_default': True, 'default_repr': 'None'}]",
108,106,method,_assert_covariates,timesfm.xreg_lib.BatchedInContextXRegBase._assert_covariates,timesfm.xreg_lib,Verifies the validity of the covariate inputs.,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'assert_covariate_shapes', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'bool', 'has_default': True, 'default_repr': 'False'}]",
109,106,method,create_covariate_matrix,timesfm.xreg_lib.BatchedInContextXRegBase.create_covariate_matrix,timesfm.xreg_lib,"Creates target vector and covariate matrices for in context regression.\n\nHere we use model fitting language to refer to the context as 'train' and\nthe horizon as 'test'.\n\nArgs:\n one_hot_encoder_drop: Which drop strategy to use for the one hot encoder.\n use_intercept: Whether to prepare an intercept (all 1) column in the\n matrices.\n assert_covariates: Whether to assert the validity of the covariate inputs.\n assert_covariate_shapes: Whether to assert the shapes of the covariate\n inputs when `assert_covariates` is True.\n\nReturns:\n A tuple of the target vector, the covariate matrix for the context, and\n the covariate matrix for the horizon.","[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'one_hot_encoder_drop', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'str | None', 'has_default': True, 'default_repr': ''first''}, {'name': 'use_intercept', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'bool', 'has_default': True, 'default_repr': 'True'}, {'name': 'assert_covariates', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'bool', 'has_default': True, 'default_repr': 'False'}, {'name': 'assert_covariate_shapes', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'bool', 'has_default': True, 'default_repr': 'False'}]","tuple[np.ndarray, np.ndarray, np.ndarray]"
110,106,method,fit,timesfm.xreg_lib.BatchedInContextXRegBase.fit,timesfm.xreg_lib,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",Any
112,111,method,fit,timesfm.xreg_lib.BatchedInContextXRegLinear.fit,timesfm.xreg_lib,"Fits a linear model for in-context regression.\n\nArgs:\n ridge: A non-negative value for specifying the ridge regression penalty.\n If 0 is provided, fallback to ordinary least squares. Note this penalty\n is added to the normalized covariate matrix.\n one_hot_encoder_drop: Which drop strategy to use for the one hot encoder.\n use_intercept: Whether to prepare an intercept (all 1) column in the\n matrices.\n force_on_cpu: Whether to force execution on cpu for accelerator machines.\n max_rows_per_col: How many rows to subsample per column. 0 for no\n subsampling. This is for speeding up model fitting.\n max_rows_per_col_sample_seed: The seed for the subsampling if needed by\n `max_rows_per_col`.\n debug_info: Whether to return debug info.\n assert_covariates: Whether to assert the validity of the covariate inputs.\n assert_covariate_shapes: Whether to assert the shapes of the covariate\n inputs when `assert_covariates` is True.\n\nReturns:\n If `debug_info` is False:\n The linear fits on the horizon.\n If `debug_info` is True:\n A tuple of:\n - the linear fits on the horizon,\n - the linear fits on the context,\n - the flattened target vector,\n - the covariate matrix for the context, and\n - the covariate matrix for the horizon.","[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'ridge', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'float', 'has_default': True, 'default_repr': '0.0'}, {'name': 'one_hot_encoder_drop', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'str | None', 'has_default': True, 'default_repr': ''first''}, {'name': 'use_intercept', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'bool', 'has_default': True, 'default_repr': 'True'}, {'name': 'force_on_cpu', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'bool', 'has_default': True, 'default_repr': 'False'}, {'name': 'max_rows_per_col', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': True, 'default_repr': '0'}, {'name': 'max_rows_per_col_sample_seed', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': True, 'default_repr': '42'}, {'name': 'debug_info', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'bool', 'has_default': True, 'default_repr': 'False'}, {'name': 'assert_covariates', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'bool', 'has_default': True, 'default_repr': 'False'}, {'name': 'assert_covariate_shapes', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'bool', 'has_default': True, 'default_repr': 'False'}]","list[np.ndarray] | tuple[list[np.ndarray], list[np.ndarray], jax.Array, jax.Array, jax.Array]"
123,122,method,setup,timesfm.patched_decoder.ResidualBlock.setup,timesfm.patched_decoder,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",
124,122,method,__call__,timesfm.patched_decoder.ResidualBlock.__call__,timesfm.patched_decoder,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'inputs', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'JTensor', 'has_default': False, 'default_repr': ''}]",JTensor
128,127,method,setup,timesfm.patched_decoder.PatchedTimeSeriesDecoder.setup,timesfm.patched_decoder,Construct the model.,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",
129,127,method,transform_decode_state,timesfm.patched_decoder.PatchedTimeSeriesDecoder.transform_decode_state,timesfm.patched_decoder,Transforms all decode state variables based on transform_fn.,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'transform_fn', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'base_layer.DecodeStateTransformFn', 'has_default': False, 'default_repr': ''}]",
130,127,method,_forward_transform,timesfm.patched_decoder.PatchedTimeSeriesDecoder._forward_transform,timesfm.patched_decoder,"Input is of shape [B, N, P].","[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'inputs', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'JTensor', 'has_default': False, 'default_repr': ''}, {'name': 'patched_pads', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'JTensor', 'has_default': False, 'default_repr': ''}]","Tuple[JTensor, Tuple[JTensor, JTensor]]"
131,127,method,_reverse_transform,timesfm.patched_decoder.PatchedTimeSeriesDecoder._reverse_transform,timesfm.patched_decoder,"Output is of shape [B, N, P, Q].","[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'outputs', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'JTensor', 'has_default': False, 'default_repr': ''}, {'name': 'stats', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Tuple[JTensor, JTensor]', 'has_default': False, 'default_repr': ''}]",JTensor
132,127,method,_preprocess_input,timesfm.patched_decoder.PatchedTimeSeriesDecoder._preprocess_input,timesfm.patched_decoder,Preprocess input for stacked transformer.,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'input_ts', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'JTensor', 'has_default': False, 'default_repr': ''}, {'name': 'input_padding', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'JTensor', 'has_default': False, 'default_repr': ''}, {'name': 'pos_emb', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Optional[JTensor]', 'has_default': True, 'default_repr': 'None'}]","Tuple[JTensor, JTensor, Optional[Tuple[JTensor, JTensor]], JTensor]"
133,127,method,_postprocess_output,timesfm.patched_decoder.PatchedTimeSeriesDecoder._postprocess_output,timesfm.patched_decoder,Postprocess output of stacked transformer.,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'model_output', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'JTensor', 'has_default': False, 'default_repr': ''}, {'name': 'num_outputs', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': False, 'default_repr': ''}, {'name': 'stats', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Tuple[JTensor, JTensor]', 'has_default': False, 'default_repr': ''}]",JTensor
134,127,method,__call__,timesfm.patched_decoder.PatchedTimeSeriesDecoder.__call__,timesfm.patched_decoder,"PatchTST call.\n\nArgs:\n inputs: A NestedMap containing (1) input_ts: input sequence of shape [B,\n T] where T must be multiple of patch_length; (2) input_padding: that\n contains padding map.\n\nReturns:\n A nested map with two keys:\n (1) 'output_tokens' of shape [B, N, D].\n (2) 'output_ts' of shape [B, N, H, Q]\n (3) 'stats' a Tuple of statistics for renormalization.","[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'inputs', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'NestedMap', 'has_default': False, 'default_repr': ''}]",NestedMap
135,127,method,decode,timesfm.patched_decoder.PatchedTimeSeriesDecoder.decode,timesfm.patched_decoder,"Auto-regressive decoding without caching.\n\nArgs:\n inputs: input time-series and paddings. Time-series shape B x C, padding\n shape shape B x (C + H) where H is the prediction length.\n horizon_len: prediction length.\n output_patch_len: output length to be fetched from one step of\n auto-regressive decoding.\n max_len: maximum training context length.\n return_forecast_on_context: whether to return the model forecast on the\n context except the first input patch.\n\nReturns:\n Tuple of two forecasting results:\n - Point (mean) output predictions as a tensor with shape B x H'.\n - Full predictions (mean and quantiles) as a tensor with shape\n B x H' x (1 + # quantiles).\n In particular, if return_forecast_on_context is True, H' is H plus\n the forecastable context length, i.e. context_len - (first) patch_len.","[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'inputs', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'NestedMap', 'has_default': False, 'default_repr': ''}, {'name': 'horizon_len', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': False, 'default_repr': ''}, {'name': 'output_patch_len', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Optional[int]', 'has_default': True, 'default_repr': 'None'}, {'name': 'max_len', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'return_forecast_on_context', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'bool', 'has_default': True, 'default_repr': 'False'}]","tuple[JTensor, JTensor]"
137,136,method,setup,timesfm.patched_decoder.PatchedDecoderFinetuneModel.setup,timesfm.patched_decoder,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",
138,136,method,compute_predictions,timesfm.patched_decoder.PatchedDecoderFinetuneModel.compute_predictions,timesfm.patched_decoder,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'input_batch', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'NestedMap', 'has_default': False, 'default_repr': ''}]",NestedMap
139,136,method,_quantile_loss,timesfm.patched_decoder.PatchedDecoderFinetuneModel._quantile_loss,timesfm.patched_decoder,Calculates quantile loss.\n\nArgs:\n pred: B x T\n actual: B x T\n quantile: quantile at which loss is computed.\n\nReturns:\n per coordinate loss.,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'pred', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'JTensor', 'has_default': False, 'default_repr': ''}, {'name': 'actual', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'JTensor', 'has_default': False, 'default_repr': ''}, {'name': 'quantile', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'float', 'has_default': False, 'default_repr': ''}]",JTensor
140,136,method,compute_loss,timesfm.patched_decoder.PatchedDecoderFinetuneModel.compute_loss,timesfm.patched_decoder,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'prediction_output', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'NestedMap', 'has_default': False, 'default_repr': ''}, {'name': 'input_batch', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'NestedMap', 'has_default': False, 'default_repr': ''}]","Tuple[NestedMap, NestedMap]"
150,149,method,__post_init__,timesfm.timesfm_torch.TimesFmTorch.__post_init__,timesfm.timesfm_torch,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",
151,149,method,load_from_checkpoint,timesfm.timesfm_torch.TimesFmTorch.load_from_checkpoint,timesfm.timesfm_torch,Loads a checkpoint and compiles the decoder.,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'checkpoint', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'timesfm_base.TimesFmCheckpoint', 'has_default': False, 'default_repr': ''}]",
152,149,method,_forecast,timesfm.timesfm_torch.TimesFmTorch._forecast,timesfm.timesfm_torch,"Forecasts on a list of time series.\n\nArgs:\n inputs: list of time series forecast contexts. Each context time series\n should be in a format convertible to JTensor by `jnp.array`.\n freq: frequency of each context time series. 0 for high frequency\n (default), 1 for medium, and 2 for low. Notice this is different from\n the `freq` required by `forecast_on_df`.\n window_size: window size of trend + residual decomposition. If None then\n we do not do decomposition.\n forecast_context_len: optional max context length.\n return_forecast_on_context: True to return the forecast on the context\n when available, i.e. after the first input patch.\n\nReturns:\nA tuple for JTensors:\n- the mean forecast of size (# inputs, # forecast horizon),\n- the full forecast (mean + quantiles) of size\n (# inputs, # forecast horizon, 1 + # quantiles).\n\nRaises:\nValueError: If the checkpoint is not properly loaded.","[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'inputs', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Sequence[Any]', 'has_default': False, 'default_repr': ''}, {'name': 'freq', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Sequence[int] | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'window_size', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'forecast_context_len', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'return_forecast_on_context', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'bool', 'has_default': True, 'default_repr': 'False'}]","tuple[np.ndarray, np.ndarray]"
170,169,method,_logging,timesfm.timesfm_base.TimesFmBase._logging,timesfm.timesfm_base,,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 's', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",
171,169,method,__post_init__,timesfm.timesfm_base.TimesFmBase.__post_init__,timesfm.timesfm_base,Additional initialization for subclasses before checkpoint loading.,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}]",
172,169,method,__init__,timesfm.timesfm_base.TimesFmBase.__init__,timesfm.timesfm_base,Initializes the TimesFM forecast API.\n\nArgs:\n hparams: Hyperparameters of the model.\n checkpoint: Checkpoint to load. Notice `checkpoint.version` will decide\n which TimesFM version to use.,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'hparams', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'TimesFmHparams', 'has_default': False, 'default_repr': ''}, {'name': 'checkpoint', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'TimesFmCheckpoint', 'has_default': False, 'default_repr': ''}]",
173,169,method,load_from_checkpoint,timesfm.timesfm_base.TimesFmBase.load_from_checkpoint,timesfm.timesfm_base,Loads a checkpoint and compiles the decoder.,"[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'checkpoint', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'TimesFmCheckpoint', 'has_default': False, 'default_repr': ''}]",
174,169,method,_preprocess,timesfm.timesfm_base.TimesFmBase._preprocess,timesfm.timesfm_base,"Formats and pads raw inputs to feed into the model.\n\nThis function both pads each time series to match the context length, and\npads the inputs to meet the SPMD shape requirement.\n\nArgs:\n inputs: A list of 1d JTensors. Each JTensor is the context time series of\n a single forecast task.\n freq: list of frequencies\n\nReturns:\nA tuple of:\n- the padded input time series to meet the model required context.\n- the padding indicator.\n- the frequency of each input time series.\n- the number of padded examples for SPMD so that each core has the same\n number (a multiple of `batch_size`) of examples.","[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'inputs', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Sequence[np.ndarray]', 'has_default': False, 'default_repr': ''}, {'name': 'freq', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Sequence[int]', 'has_default': False, 'default_repr': ''}]","tuple[np.ndarray, np.ndarray, np.ndarray, int]"
175,169,method,_forecast,timesfm.timesfm_base.TimesFmBase._forecast,timesfm.timesfm_base,"Forecasts on a list of time series.\n\nArgs:\n inputs: list of time series forecast contexts. Each context time series\n should be in a format convertible to JTensor by `jnp.array`.\n freq: frequency of each context time series. 0 for high frequency\n (default), 1 for medium, and 2 for low. Notice this is different from\n the `freq` required by `forecast_on_df`.\n window_size: window size of trend + residual decomposition. If None then\n we do not do decomposition.\n forecast_context_len: optional max context length.\n return_forecast_on_context: True to return the forecast on the context\n when available, i.e. after the first input patch.\n\nReturns:\nA tuple for np.array:\n- the mean forecast of size (# inputs, # forecast horizon),\n- the full forecast (mean + quantiles) of size\n (# inputs, # forecast horizon, 1 + # quantiles).\n\nRaises:\nValueError: If the checkpoint is not properly loaded.","[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'inputs', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Sequence[Any]', 'has_default': False, 'default_repr': ''}, {'name': 'freq', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Sequence[int] | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'window_size', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'forecast_context_len', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'return_forecast_on_context', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'bool', 'has_default': True, 'default_repr': 'False'}]","tuple[np.ndarray, np.ndarray]"
176,169,method,forecast,timesfm.timesfm_base.TimesFmBase.forecast,timesfm.timesfm_base,"Forecasts on a list of time series.\n\nArgs:\n inputs: list of time series forecast contexts. Each context time series\n should be in a format convertible to JTensor by `jnp.array`.\n freq: frequency of each context time series. 0 for high frequency\n (default), 1 for medium, and 2 for low. Notice this is different from\n the `freq` required by `forecast_on_df`.\n window_size: window size of trend + residual decomposition. If None then\n we do not do decomposition.\n forecast_context_len: optional max context length.\n return_forecast_on_context: True to return the forecast on the context\n when available, i.e. after the first input patch.\n normalize: If True, then we normalize the inputs before forecasting and\n the outputs are then renormalized to the original scale.\n\nReturns:\nA tuple for np.array:\n- the mean forecast of size (# inputs, # forecast horizon),\n- the full forecast (mean + quantiles) of size\n (# inputs, # forecast horizon, 1 + # quantiles).\n\nRaises:\nValueError: If the checkpoint is not properly loaded.","[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'inputs', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Sequence[Any]', 'has_default': False, 'default_repr': ''}, {'name': 'freq', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Sequence[int] | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'window_size', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'forecast_context_len', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'return_forecast_on_context', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'bool', 'has_default': True, 'default_repr': 'False'}, {'name': 'normalize', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'bool', 'has_default': True, 'default_repr': 'False'}]","tuple[np.ndarray, np.ndarray]"
177,169,method,forecast_with_covariates,timesfm.timesfm_base.TimesFmBase.forecast_with_covariates,timesfm.timesfm_base,"Forecasts on a list of time series with covariates.\n\nTo optimize inference speed, avoid string valued categorical covariates.\n\nArgs:\n inputs: A list of time series forecast contexts. Each context time series\n should be in a format convertible to JTensor by `jnp.array`.\n dynamic_numerical_covariates: A dict of dynamic numerical covariates.\n dynamic_categorical_covariates: A dict of dynamic categorical covariates.\n static_numerical_covariates: A dict of static numerical covariates.\n static_categorical_covariates: A dict of static categorical covariates.\n freq: frequency of each context time series. 0 for high frequency\n (default), 1 for medium, and 2 for low. Notice this is different from\n the `freq` required by `forecast_on_df`.\n window_size: window size of trend + residual decomposition. If None then\n we do not do decomposition.\n forecast_context_len: optional max context length.\n xreg_mode: one of ""xreg + timesfm"" or ""timesfm + xreg"". ""xreg + timesfm""\n fits a model on the residuals of the TimesFM forecast. ""timesfm + xreg""\n fits a model on the targets then forecasts on the residuals via TimesFM.\n normalize_xreg_target_per_input: whether to normalize the xreg target per\n input in the given batch.\n ridge: ridge penalty for the linear model.\n max_rows_per_col: max number of rows per column for the linear model.\n force_on_cpu: whether to force running on cpu for the linear model.\n\nReturns:\n A tuple of two lists. The first is the outputs of the model. The second is\n the outputs of the xreg.","[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'inputs', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'list[Sequence[float]]', 'has_default': False, 'default_repr': ''}, {'name': 'dynamic_numerical_covariates', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'dict[str, Sequence[Sequence[float]]] | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'dynamic_categorical_covariates', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'dict[str, Sequence[Sequence[Category]]] | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'static_numerical_covariates', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'dict[str, Sequence[float]] | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'static_categorical_covariates', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'dict[str, Sequence[Category]] | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'freq', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'Sequence[int] | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'window_size', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'forecast_context_len', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'xreg_mode', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'XRegMode', 'has_default': True, 'default_repr': ''xreg + timesfm''}, {'name': 'normalize_xreg_target_per_input', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'bool', 'has_default': True, 'default_repr': 'True'}, {'name': 'ridge', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'float', 'has_default': True, 'default_repr': '0.0'}, {'name': 'max_rows_per_col', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': True, 'default_repr': '0'}, {'name': 'force_on_cpu', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'bool', 'has_default': True, 'default_repr': 'False'}]",
178,169,method,forecast_on_df,timesfm.timesfm_base.TimesFmBase.forecast_on_df,timesfm.timesfm_base,"Forecasts on a list of time series.\n\nArgs:\n inputs: A pd.DataFrame of all time series. The dataframe should have a\n `unique_id` column for identifying the time series, a `ds` column for\n timestamps and a value column for the time series values.\n freq: string valued `freq` of data. Notice this is different from the\n `freq` required by `forecast`. See `freq_map` for allowed values.\n forecast_context_len: If provided none zero, we take the last\n `forecast_context_len` time-points from each series as the forecast\n context instead of the `context_len` set by the model.\n value_name: The name of the value column.\n model_name: name of the model to be written into future df.\n window_size: window size of trend + residual decomposition. If None then\n we do not do decomposition.\n num_jobs: number of parallel processes to use for dataframe processing.\n normalize: normalize context before forecasting or not.\n verbose: output model states in terminal.\n\nReturns:\n Future forecasts dataframe.","[{'name': 'self', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': '', 'has_default': False, 'default_repr': ''}, {'name': 'inputs', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'pd.DataFrame', 'has_default': False, 'default_repr': ''}, {'name': 'freq', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'str', 'has_default': False, 'default_repr': ''}, {'name': 'forecast_context_len', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': True, 'default_repr': '0'}, {'name': 'value_name', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'str', 'has_default': True, 'default_repr': ''values''}, {'name': 'model_name', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'str', 'has_default': True, 'default_repr': ''timesfm''}, {'name': 'window_size', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int | None', 'has_default': True, 'default_repr': 'None'}, {'name': 'num_jobs', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'int', 'has_default': True, 'default_repr': '1'}, {'name': 'normalize', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'bool', 'has_default': True, 'default_repr': 'False'}, {'name': 'verbose', 'kind': 'POSITIONAL_OR_KEYWORD', 'annotation': 'bool', 'has_default': True, 'default_repr': 'True'}]",pd.DataFrame
